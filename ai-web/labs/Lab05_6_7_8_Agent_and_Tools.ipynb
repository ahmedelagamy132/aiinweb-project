{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bcfa1e",
   "metadata": {},
   "source": [
    "\n",
    "## Updated full-stack template walkthrough\n",
    "\n",
    "This lab now uses a Postgres-backed stack managed through Alembic migrations and Docker Compose.\n",
    "\n",
    "- **Database + Alembic**: `backend/alembic/env.py` and `backend/alembic/versions/20250212_initial.py` create tables for echo retries, planner runs, course resources, and RAG document chunks. The new `20250529_agent_runs.py` migration adds the `agent_runs` table for persisting agent executions. Run migrations with `alembic upgrade head` (the backend container executes this automatically on start).\n",
    "- **FastAPI wiring**: `backend/app/database.py` exposes a SQLAlchemy `SessionLocal` dependency. Routers like `app/routers/echo.py`, `app/routers/planner.py`, `app/routers/resources.py`, and `app/routers/agent.py` read and write real rows instead of in-memory mocks.\n",
    "- **Docker Compose + Nginx**: `docker-compose.yml` now launches Postgres, FastAPI (with migrations), the Vite dev server, and an Nginx reverse proxy (`nginx/default.conf`) that fronts both the API (`/api`) and frontend assets.\n",
    "- **RAG chatbot + Agent**: `app/services/rag.py` indexes seeded `DocumentChunk` rows, while `app/services/chatbot.py` blends retrieval with Gemini when `GEMINI_API_KEY` is configured. The release readiness agent also uses RAG to retrieve relevant documentation.\n",
    "- **AI-powered Agent**: The release readiness agent now integrates Gemini for generating strategic insights and AI-powered recommendations, FAISS for RAG retrieval, and persists all runs to the database for auditing.\n",
    "\n",
    "### How to run the stack with Docker Compose\n",
    "\n",
    "1. `cd ai-web`\n",
    "2. `docker compose up --build`\n",
    "3. Open http://localhost:8080 to reach Nginx. API requests are proxied to FastAPI at `/api`. Postgres data lives in the `db_data` volume.\n",
    "\n",
    "### Creating and applying new migrations\n",
    "\n",
    "1. Enter the backend container: `docker compose exec backend bash`\n",
    "2. Generate a migration: `alembic revision -m \"describe change\" --autogenerate`\n",
    "3. Apply migrations: `alembic upgrade head`\n",
    "\n",
    "### Testing the new features\n",
    "\n",
    "- **Echo retry + persistence**: Submit the echo form; the \"Recent echo attempts\" list should update from the `echo_attempts` table.\n",
    "- **Resource Board**: Add a URL in the Resource Board. Refreshing the page keeps entries thanks to the `resources` table.\n",
    "- **Planner + history**: Generate a plan in the Planner panel; the newest plan appears in the history list powered by the `plan_runs` table.\n",
    "- **Release Readiness Agent**: Select a feature, run the agent, and see AI-powered recommendations with Gemini insights, RAG-retrieved context, and historical runs from the `agent_runs` table.\n",
    "\n",
    "Refer to the updated source files when walking through the lab so students can trace how migrations, database sessions, and the React UI connect end to end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a966c8",
   "metadata": {},
   "source": [
    "\n",
    "## Why Nginx, Alembic, and FAISS matter for this stack\n",
    "\n",
    "**Nginx reverse proxy**\n",
    "- *What it is*: A lightweight web server that terminates HTTP, proxies requests, and serves static assets.\n",
    "- *How we integrated it*: `docker-compose.yml` launches an `nginx` service with `nginx/default.conf` routing `/api/` to FastAPI (port 8000) and everything else to the Vite dev server (port 5173). This keeps the release readiness endpoint (`/api/ai/release-readiness`) and the React UI on a single origin behind http://localhost:8080.\n",
    "- *Why we adopted it*: A unified front door eliminates CORS headaches and mirrors production topologies where a reverse proxy fronts both the SPA and API.\n",
    "- *If we removed it*: Students would juggle multiple ports, browser `fetch` calls would hit CORS errors, and any deployed version would need a different networking story than the local lab.\n",
    "\n",
    "**Alembic migrations**\n",
    "- *What it is*: A schema migration tool for SQLAlchemy projects so database changes are reproducible and versioned.\n",
    "- *How we integrated it*: `backend/alembic/env.py` reads `DATABASE_URL`, and migrations create tables for echo retries, plan runs, resources, RAG document chunks, and now agent runs. The backend container runs `python -m alembic upgrade head` before starting Uvicorn, so every boot applies the latest schema and seeds data.\n",
    "- *Why we adopted it*: Planner history, the resources board, RAG context for the chatbot, and agent execution history all live in Postgres. Alembic keeps the schema in sync across teammates so future agent runs can safely persist outputs or read existing context without surprises.\n",
    "- *If we removed it*: Each developer would run ad hoc SQL by hand, migrations would get lost, and any endpoint touching `plan_runs`, `resources`, `document_chunks`, or `agent_runs` would fail at runtime.\n",
    "\n",
    "**FAISS retrieval**\n",
    "- *What it is*: A fast similarity search library for vector embeddings, used here for lightweight RAG.\n",
    "- *How we integrated it*: `app/services/rag.py` normalizes document embeddings and loads them into a FAISS `IndexFlatL2`; both the chatbot service and the release readiness agent call `build_retriever()` to fetch the top context chunks before generating an answer or recommendations.\n",
    "- *Why we adopted it*: It gives agents a deterministic context window without external APIs, so answers stay grounded in the course docs even offline.\n",
    "- *If we removed it*: The chatbot and agent would fall back to generic responses with no retrieved evidence, reducing accuracy and making the lab less realistic.\n",
    "\n",
    "### Agent foundation at a glance\n",
    "- **Tools**: `app/services/agent_tools.py` defines deterministic product briefs, launch windows, support contacts, and SLO watch items so the agent has stable inputs.\n",
    "- **RAG Integration**: The agent retrieves relevant documentation using FAISS before generating recommendations.\n",
    "- **Gemini AI**: When `GEMINI_API_KEY` is configured, the agent uses Gemini to generate strategic insights and AI-powered recommendations.\n",
    "- **Database Persistence**: All agent runs are saved to the `agent_runs` table for auditing and learning.\n",
    "- **Orchestration**: `run_release_readiness_agent()` in `app/services/agent.py` sequences tool calls, retrieves RAG context, calls Gemini, builds a plan, persists the run, and returns structured recommendations with tool traces.\n",
    "- **API surface**: `app/routers/agent.py` exposes `/ai/release-readiness`, `/ai/history`, and `/ai/features`, keeping the router thin and delegating all logic to the service layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faiss_embeddings_deep_dive",
   "metadata": {},
   "source": [
    "## Deep Dive: FAISS, Embeddings, and RAG Integration\n",
    "\n",
    "### Understanding Embeddings\n",
    "\n",
    "**What are embeddings?**\n",
    "Embeddings are numerical representations of text (or other data) that capture semantic meaning. Think of them as coordinates in a high-dimensional space where semantically similar texts are positioned close together.\n",
    "\n",
    "**Why do we need embeddings?**\n",
    "- **Semantic search**: Find documents by meaning, not just keyword matching\n",
    "- **Similarity comparison**: Determine how similar two pieces of text are\n",
    "- **Efficient retrieval**: Search through millions of documents quickly\n",
    "\n",
    "**How embeddings work:**\n",
    "1. **Text \u2192 Vector**: Convert text into a fixed-size numerical vector (e.g., 256 or 768 dimensions)\n",
    "2. **Semantic proximity**: Similar meanings produce similar vectors\n",
    "3. **Distance metrics**: Use cosine similarity or L2 distance to find similar vectors\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "# Simplified conceptual example\n",
    "embed(\"FastAPI tutorial\") \u2192 [0.2, 0.8, ..., 0.5]  # 256 numbers\n",
    "embed(\"FastAPI guide\")    \u2192 [0.3, 0.7, ..., 0.4]  # Very similar!\n",
    "embed(\"Pizza recipe\")     \u2192 [0.9, 0.1, ..., 0.2]  # Very different\n",
    "```\n",
    "\n",
    "### What is FAISS?\n",
    "\n",
    "**FAISS (Facebook AI Similarity Search)** is a library developed by Meta for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "**Key features:**\n",
    "- **Speed**: Search billions of vectors in milliseconds\n",
    "- **Scalability**: Works on CPU and GPU\n",
    "- **Flexibility**: Multiple index types for different use cases\n",
    "- **Memory efficiency**: Optimized data structures\n",
    "\n",
    "**Common FAISS index types:**\n",
    "1. **IndexFlatL2**: Exact search using L2 (Euclidean) distance\n",
    "   - Most accurate, good for small datasets\n",
    "   - Our implementation uses this for simplicity\n",
    "2. **IndexFlatIP**: Exact search using inner product (cosine similarity)\n",
    "   - Good when vectors are normalized\n",
    "3. **IndexIVFFlat**: Approximate search with inverted file index\n",
    "   - Faster for large datasets, slight accuracy tradeoff\n",
    "\n",
    "### How RAG (Retrieval-Augmented Generation) Works\n",
    "\n",
    "**RAG combines retrieval and generation:**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  User Query: \"How do I deploy the agent?\"           \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  Step 1: Embed Query                                \u2502\n",
    "\u2502  query_vector = embed(\"How do I deploy the agent?\") \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  Step 2: FAISS Search                               \u2502\n",
    "\u2502  Find top 3 most similar document chunks            \u2502\n",
    "\u2502  Results: [doc1 (score: 0.23), doc2 (0.45), ...]   \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  Step 3: Build Context                              \u2502\n",
    "\u2502  Combine retrieved chunks into a context string     \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  Step 4: Generate with AI                           \u2502\n",
    "\u2502  Pass context + query to Gemini for answer         \u2502\n",
    "\u2502  Result: Grounded, accurate response                \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Why RAG is powerful:**\n",
    "- **Grounding**: AI responses are backed by actual documents\n",
    "- **Up-to-date**: Add new documents without retraining\n",
    "- **Transparency**: Show which documents were used\n",
    "- **Reduced hallucination**: AI has factual context to work with\n",
    "\n",
    "### Our RAG Implementation in `app/services/rag.py`\n",
    "\n",
    "Let's break down how our implementation works:\n",
    "\n",
    "#### 1. Creating Embeddings (Deterministic)\n",
    "\n",
    "```python\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    \"\"\"Create a deterministic hashed embedding without external dependencies.\"\"\"\n",
    "    vector = np.zeros(EMBED_DIM, dtype=\"float32\")  # 256 dimensions\n",
    "    for token in _tokenize(text):  # Split text into words\n",
    "        vector[hash(token) % EMBED_DIM] += 1.0  # Hash each word to a dimension\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm:\n",
    "        vector /= norm  # Normalize to unit length\n",
    "    return vector\n",
    "```\n",
    "\n",
    "**What's happening:**\n",
    "- Uses a **bag-of-words** approach with hashing\n",
    "- Each word maps to a dimension via hash function\n",
    "- Normalizes the vector so all vectors have length 1\n",
    "- **Why deterministic?** Same text always produces same embedding (no API calls, offline-friendly)\n",
    "- **Production alternative:** Use real embedding models like `text-embedding-004` from Gemini or OpenAI's embeddings\n",
    "\n",
    "#### 2. Building the FAISS Index\n",
    "\n",
    "```python\n",
    "class Retriever:\n",
    "    def __init__(self, chunks: Sequence[DocumentChunk]):\n",
    "        self.chunks = list(chunks)\n",
    "        if not self.chunks:\n",
    "            self.index = None\n",
    "            return\n",
    "\n",
    "        # Create FAISS index for L2 (Euclidean) distance\n",
    "        self.index = faiss.IndexFlatL2(EMBED_DIM)  # 256 dimensions\n",
    "        \n",
    "        # Stack all embeddings into a numpy array\n",
    "        embeddings = np.stack([\n",
    "            np.array(chunk.embedding, dtype=\"float32\") \n",
    "            for chunk in self.chunks\n",
    "        ])\n",
    "        \n",
    "        # Add to index (builds internal data structures)\n",
    "        self.index.add(embeddings)\n",
    "```\n",
    "\n",
    "**What's happening:**\n",
    "- Creates a FAISS index that uses **L2 distance** (Euclidean distance)\n",
    "- Loads all pre-computed embeddings from database\n",
    "- Adds them to FAISS index for fast searching\n",
    "\n",
    "#### 3. Searching for Relevant Context\n",
    "\n",
    "```python\n",
    "def search(self, query: str, k: int = 3) -> list[RetrievedContext]:\n",
    "    if not self.index or not self.chunks:\n",
    "        return []\n",
    "\n",
    "    # Embed the query\n",
    "    query_vector = np.expand_dims(embed_text(query), axis=0)\n",
    "    \n",
    "    # Search FAISS index for k nearest neighbors\n",
    "    distances, indices = self.index.search(query_vector, min(k, len(self.chunks)))\n",
    "    \n",
    "    # Build results with content, source, and score\n",
    "    results: list[RetrievedContext] = []\n",
    "    for score, idx in zip(distances[0], indices[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        chunk = self.chunks[idx]\n",
    "        results.append(\n",
    "            RetrievedContext(\n",
    "                content=chunk.content,\n",
    "                source=chunk.source,\n",
    "                score=float(score)  # Lower is better for L2 distance\n",
    "            )\n",
    "        )\n",
    "    return results\n",
    "```\n",
    "\n",
    "**What's happening:**\n",
    "1. **Embed the query** using the same function as documents\n",
    "2. **Search FAISS** for the k closest vectors\n",
    "3. **Return results** with the actual content, source, and similarity score\n",
    "4. **Lower score = more similar** (L2 distance)\n",
    "\n",
    "#### 4. Integration in the Agent\n",
    "\n",
    "The agent uses RAG in `app/services/agent.py`:\n",
    "\n",
    "```python\n",
    "# Build retriever from database chunks\n",
    "retriever = build_retriever(db)\n",
    "\n",
    "# Create search query combining feature name and context\n",
    "search_query = f\"{brief.name} {context.audience_role} release launch\"\n",
    "\n",
    "# Retrieve top 3 relevant chunks\n",
    "rag_contexts = retriever.search(search_query, k=3)\n",
    "\n",
    "# Pass to Gemini for AI-powered insights\n",
    "gemini_insight, ai_recommendations = _generate_gemini_insight(\n",
    "    brief, launch_window, slo_items, rag_contexts, context\n",
    ")\n",
    "```\n",
    "\n",
    "**The flow:**\n",
    "1. **Load** all document chunks from PostgreSQL\n",
    "2. **Build** FAISS index from embeddings\n",
    "3. **Search** for relevant context based on feature + audience\n",
    "4. **Pass** retrieved context to Gemini along with other data\n",
    "5. **Generate** AI-powered recommendations grounded in documentation\n",
    "\n",
    "### Why This Matters for Production\n",
    "\n",
    "**Without RAG:**\n",
    "```\n",
    "User: \"How do I deploy the agent?\"\n",
    "AI: \"You can deploy using Docker or Kubernetes...\"  # Generic answer, might be wrong\n",
    "```\n",
    "\n",
    "**With RAG:**\n",
    "```\n",
    "User: \"How do I deploy the agent?\"\n",
    "System: [Retrieves actual deployment docs]\n",
    "AI: \"According to the deployment guide, run `docker compose up --build` \n",
    "     in the ai-web directory. The agent will be available at localhost:8080.\"\n",
    "     # Accurate, grounded in actual docs\n",
    "```\n",
    "\n",
    "**Key benefits:**\n",
    "- **Accuracy**: Answers come from verified documentation\n",
    "- **Auditability**: Can show which docs were used\n",
    "- **Maintainability**: Update docs without retraining AI\n",
    "- **Cost-effective**: No need to fine-tune models\n",
    "\n",
    "### Performance Considerations\n",
    "\n",
    "**Current implementation:**\n",
    "- **Index type**: IndexFlatL2 (exact search)\n",
    "- **Embedding method**: Deterministic hashing\n",
    "- **Dataset size**: Dozens of chunks (course docs)\n",
    "- **Speed**: Milliseconds per search\n",
    "\n",
    "**For production scale:**\n",
    "- **Larger datasets** (millions of chunks): Use `IndexIVFFlat` or `IndexHNSW`\n",
    "- **Better embeddings**: Switch to `text-embedding-004` from Gemini\n",
    "- **Caching**: Cache frequent queries to avoid repeated searches\n",
    "- **Reranking**: Use a second model to rerank retrieved results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2cc28",
   "metadata": {},
   "source": [
    "# Lab 05 \u00b7 AI-Powered Release Readiness Agent\n",
    "\n",
    "*This lab notebook provides guided steps. All commands are intended for local execution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15651818",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Build a production-grade release readiness agent that integrates with Gemini AI, FAISS RAG, and database persistence.\n",
    "- Provide credible tool abstractions for product briefs, launch windows, and stakeholder contacts.\n",
    "- Expose `/ai/release-readiness`, `/ai/history`, and `/ai/features` endpoints that return structured recommendations.\n",
    "- Persist agent runs to the database for auditing and learning from past executions.\n",
    "\n",
    "In this lab, you will build a **production-grade AI-powered agent** that demonstrates:\n",
    "\n",
    "1. **Model an agent workflow**: Learn how agents orchestrate multiple tools, RAG retrieval, and AI calls to accomplish complex tasks\n",
    "2. **Build tool abstractions**: Create reusable functions that agents can call to gather information\n",
    "3. **Integrate AI capabilities**: Use Gemini to generate intelligent insights and recommendations\n",
    "4. **Implement RAG**: Retrieve relevant documentation using FAISS to ground agent responses\n",
    "5. **Persist agent runs**: Store execution history in PostgreSQL for auditing and learning\n",
    "6. **Structure agent responses**: Return well-formatted JSON with AI insights, recommendations, and tool traces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da98749",
   "metadata": {},
   "source": [
    "## What will be learned\n",
    "- Integrating Gemini AI for generating strategic insights and recommendations.\n",
    "- Using FAISS-backed RAG to retrieve relevant documentation.\n",
    "- Persisting agent runs to PostgreSQL for auditing and compliance.\n",
    "- Coordinating multiple service helpers inside an agent workflow.\n",
    "- Returning Pydantic models that the frontend can render without extra parsing.\n",
    "- Logging tool invocations to aid observability and debugging.\n",
    "\n",
    "By the end of this lab, you will understand:\n",
    "\n",
    "### Core Concepts\n",
    "- **Agent Architecture**: How agents break down complex tasks into smaller tool calls, RAG retrieval, and AI generation\n",
    "- **Tool Design**: Creating focused functions that do one thing well\n",
    "- **RAG Integration**: Retrieving relevant context to ground AI responses\n",
    "- **AI Integration**: Using Gemini to generate intelligent insights\n",
    "- **Database Persistence**: Storing agent runs for auditing and learning\n",
    "- **Service Layer Pattern**: Separating business logic from API routing\n",
    "\n",
    "### Technical Skills\n",
    "- **Coordinating service helpers**: Calling multiple functions within an agent workflow\n",
    "- **Pydantic models**: Defining schemas that validate data and generate documentation\n",
    "- **Error handling**: Gracefully managing missing data or invalid inputs\n",
    "- **Logging tool invocations**: Tracking which tools were called and what they returned\n",
    "- **Priority-based recommendations**: Categorizing actions by urgency (high/medium/low)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b18c2",
   "metadata": {},
   "source": [
    "## Prerequisites & install\n",
    "Reuse the virtual environment created earlier in the course. The required dependencies are already in `requirements.txt`.\n",
    "\n",
    "```bash\n",
    "cd ai-web/backend\n",
    ". .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Environment Setup\n",
    "Reuse the virtual environment created earlier in the course. This lab builds on the FastAPI foundation from previous labs.\n",
    "\n",
    "### Required Dependencies\n",
    "The following are needed (already in requirements.txt):\n",
    "- `pydantic` - Data validation and type hints\n",
    "- `google-generativeai` - Gemini API client\n",
    "- `faiss-cpu` - FAISS vector similarity search\n",
    "- `sqlalchemy` - Database ORM\n",
    "- `alembic` - Database migrations\n",
    "\n",
    "### Gemini API Key (Optional but Recommended)\n",
    "To enable AI-powered insights, add your Gemini API key to `backend/.env`:\n",
    "```\n",
    "GEMINI_API_KEY=your-api-key-here\n",
    "```\n",
    "The agent works without it but will only return deterministic recommendations.\n",
    "\n",
    "### Verification\n",
    "Ensure your backend is running and accessible:\n",
    "```bash\n",
    "curl http://localhost:8000/health\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ada4db",
   "metadata": {},
   "source": [
    "## Step-by-step tasks\n",
    "Build out the tools, service, and router layers needed to run the AI-powered release readiness agent.\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "Before diving into code, let's understand the enhanced architecture:\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  FastAPI Router (agent.py)             \u2502  \u2190 HTTP endpoints\n",
    "\u2502  - /ai/release-readiness               \u2502\n",
    "\u2502  - /ai/history                          \u2502\n",
    "\u2502  - /ai/features                         \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                  \u2502\n",
    "                  \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  Agent Service (agent.py)               \u2502  \u2190 Business logic\n",
    "\u2502  - Orchestrates tool calls              \u2502\n",
    "\u2502  - Retrieves RAG context (FAISS)        \u2502\n",
    "\u2502  - Calls Gemini for AI insights         \u2502\n",
    "\u2502  - Persists runs to database            \u2502\n",
    "\u2502  - Builds recommendations               \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                  \u2502\n",
    "        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "        \u25bc         \u25bc         \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  Tools    \u2502 \u2502 RAG   \u2502 \u2502 Gemini  \u2502\n",
    "\u2502  (agent_  \u2502 \u2502(rag.py)\u2502 \u2502  API   \u2502\n",
    "\u2502  tools.py)\u2502 \u2502       \u2502 \u2502        \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "This separation of concerns makes the system:\n",
    "- **Testable**: Each layer can be tested independently\n",
    "- **Maintainable**: Changes to one layer don't ripple through the entire system\n",
    "- **Reusable**: Tools can be used by multiple agents\n",
    "- **Auditable**: All runs are persisted for review\n",
    "\n",
    "Let's build each layer from the bottom up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa103e09",
   "metadata": {},
   "source": [
    "### Step 1: Release data tools\n",
    "The tools in `app/services/agent_tools.py` provide deterministic product data so the agent can make realistic decisions.\n",
    "\n",
    "#### What Are Tools?\n",
    "Tools are **focused functions** that agents call to gather information or perform actions. Each tool should:\n",
    "- Do **one thing well**\n",
    "- Have **clear inputs and outputs**\n",
    "- Be **stateless** (no hidden dependencies)\n",
    "- Return **structured data** (Pydantic models, not raw dicts)\n",
    "\n",
    "#### The Four Core Tools\n",
    "\n",
    "1. **`fetch_feature_brief(feature_slug)`**: Returns product information\n",
    "2. **`fetch_launch_window(feature_slug)`**: Returns deployment timing\n",
    "3. **`fetch_support_contacts(audience_role)`**: Returns stakeholders to notify\n",
    "4. **`list_slo_watch_items(feature_slug)`**: Returns reliability concerns\n",
    "\n",
    "Review the existing implementation in `app/services/agent_tools.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54450c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the existing tools\n",
    "from app.services.agent_tools import (\n",
    "    fetch_feature_brief,\n",
    "    fetch_launch_window,\n",
    "    fetch_support_contacts,\n",
    "    list_slo_watch_items,\n",
    ")\n",
    "\n",
    "# Test each tool\n",
    "print(\"Feature Brief:\")\n",
    "print(fetch_feature_brief(\"curriculum-pathways\").model_dump())\n",
    "print(\"\\nLaunch Window:\")\n",
    "print(fetch_launch_window(\"curriculum-pathways\").model_dump())\n",
    "print(\"\\nSupport Contacts:\")\n",
    "print([c.model_dump() for c in fetch_support_contacts(\"Instructor\")])\n",
    "print(\"\\nSLO Watch Items:\")\n",
    "print(list_slo_watch_items(\"curriculum-pathways\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708bd7b",
   "metadata": {},
   "source": [
    "### Step 2: AI-Powered Agent Service\n",
    "The agent service in `app/services/agent.py` orchestrates tools, RAG, Gemini, and database persistence.\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "**1. Tool Orchestration**\n",
    "The agent calls tools to gather context:\n",
    "```python\n",
    "brief = fetch_feature_brief(context.feature_slug)\n",
    "launch_window = fetch_launch_window(context.feature_slug)\n",
    "contacts = fetch_support_contacts(context.audience_role)\n",
    "slo_watch_items = list_slo_watch_items(context.feature_slug)\n",
    "```\n",
    "\n",
    "**2. RAG Retrieval (FAISS)**\n",
    "The agent retrieves relevant documentation:\n",
    "```python\n",
    "retriever = build_retriever(db)\n",
    "rag_contexts = retriever.search(search_query, k=3)\n",
    "```\n",
    "\n",
    "**3. Gemini AI Insights**\n",
    "When configured, Gemini generates strategic insights:\n",
    "```python\n",
    "gemini_insight, ai_recommendations = _generate_gemini_insight(\n",
    "    brief, launch_window, slo_items, rag_contexts, context\n",
    ")\n",
    "```\n",
    "\n",
    "**4. Database Persistence**\n",
    "All runs are saved for auditing:\n",
    "```python\n",
    "agent_run = AgentRun(\n",
    "    feature_slug=context.feature_slug,\n",
    "    summary=summary,\n",
    "    gemini_insight=gemini_insight,\n",
    "    recommended_actions=[...],\n",
    "    tool_calls=[...],\n",
    "    rag_contexts=[...],\n",
    "    used_gemini=used_gemini,\n",
    ")\n",
    "db.add(agent_run)\n",
    "db.commit()\n",
    "```\n",
    "\n",
    "#### Enhanced Output Structure\n",
    "\n",
    "```python\n",
    "class AgentRunResult(BaseModel):\n",
    "    summary: str\n",
    "    gemini_insight: str | None = None  # AI-generated insight\n",
    "    recommended_actions: list[AgentRecommendation]  # With priority levels\n",
    "    plan: Plan\n",
    "    tool_calls: list[AgentToolCall]  # Includes RAG and Gemini calls\n",
    "    rag_contexts: list[RAGContext] = []  # Retrieved documents\n",
    "    used_gemini: bool = False  # Whether Gemini was used\n",
    "```\n",
    "\n",
    "#### Recommendation Priorities\n",
    "\n",
    "Recommendations now have priority levels:\n",
    "```python\n",
    "class AgentRecommendation(BaseModel):\n",
    "    title: str\n",
    "    detail: str\n",
    "    priority: Literal[\"high\", \"medium\", \"low\"] = \"medium\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70444e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the agent service structure\n",
    "from app.services.agent import (\n",
    "    AgentRunContext,\n",
    "    AgentRunResult,\n",
    "    AgentRecommendation,\n",
    "    AgentToolCall,\n",
    "    RAGContext,\n",
    ")\n",
    "\n",
    "# Show the enhanced models\n",
    "print(\"AgentRunResult fields:\")\n",
    "for name, field in AgentRunResult.model_fields.items():\n",
    "    print(f\"  - {name}: {field.annotation}\")\n",
    "\n",
    "print(\"\\nAgentRecommendation fields:\")\n",
    "for name, field in AgentRecommendation.model_fields.items():\n",
    "    print(f\"  - {name}: {field.annotation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666451f",
   "metadata": {},
   "source": [
    "### Step 3: API Router with Multiple Endpoints\n",
    "The router in `app/routers/agent.py` exposes three endpoints.\n",
    "\n",
    "#### Endpoint 1: `/ai/release-readiness` (POST)\n",
    "Runs the agent and returns structured recommendations:\n",
    "```python\n",
    "@router.post(\"/release-readiness\", response_model=AgentRunResult)\n",
    "def release_readiness(\n",
    "    payload: AgentRunContext,\n",
    "    db: Session = Depends(get_db),\n",
    ") -> AgentRunResult:\n",
    "    return run_release_readiness_agent(payload, db=db)\n",
    "```\n",
    "\n",
    "#### Endpoint 2: `/ai/history` (GET)\n",
    "Returns historical agent runs for auditing:\n",
    "```python\n",
    "@router.get(\"/history\", response_model=AgentHistoryResponse)\n",
    "def agent_history(\n",
    "    feature_slug: str | None = Query(None),\n",
    "    limit: int = Query(10, ge=1, le=50),\n",
    "    db: Session = Depends(get_db),\n",
    ") -> AgentHistoryResponse:\n",
    "    runs = get_agent_history(db, feature_slug=feature_slug, limit=limit)\n",
    "    return AgentHistoryResponse(runs=items, total=len(items))\n",
    "```\n",
    "\n",
    "#### Endpoint 3: `/ai/features` (GET)\n",
    "Lists available features for the agent:\n",
    "```python\n",
    "@router.get(\"/features\")\n",
    "def list_available_features() -> dict[str, Any]:\n",
    "    # Returns feature metadata for frontend dropdowns\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42558454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The router is already configured. Verify the endpoints exist:\n",
    "from app.routers.agent import router\n",
    "\n",
    "print(\"Agent router endpoints:\")\n",
    "for route in router.routes:\n",
    "    if hasattr(route, 'methods'):\n",
    "        print(f\"  {list(route.methods)[0]:6} {route.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0d1cc",
   "metadata": {},
   "source": [
    "### Step 4: Database Model for Agent Runs\n",
    "The `AgentRun` model in `app/models.py` persists agent executions.\n",
    "\n",
    "```python\n",
    "class AgentRun(Base):\n",
    "    __tablename__ = \"agent_runs\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    feature_slug: Mapped[str] = mapped_column(String(120), index=True)\n",
    "    audience_role: Mapped[str] = mapped_column(String(120))\n",
    "    audience_experience: Mapped[str] = mapped_column(String(32))\n",
    "    summary: Mapped[str] = mapped_column(Text)\n",
    "    gemini_insight: Mapped[str | None] = mapped_column(Text, nullable=True)\n",
    "    recommended_actions: Mapped[Any] = mapped_column(JSONB)\n",
    "    tool_calls: Mapped[Any] = mapped_column(JSONB)\n",
    "    rag_contexts: Mapped[Any] = mapped_column(JSONB, default=list)\n",
    "    used_gemini: Mapped[bool] = mapped_column(Boolean, default=False)\n",
    "    created_at: Mapped[datetime] = mapped_column(DateTime, default=utcnow)\n",
    "```\n",
    "\n",
    "The migration `alembic/versions/20250529_agent_runs.py` creates this table and seeds feature-related document chunks for RAG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the AgentRun model\n",
    "from app.models import AgentRun\n",
    "\n",
    "print(\"AgentRun table columns:\")\n",
    "for column in AgentRun.__table__.columns:\n",
    "    print(f\"  - {column.name}: {column.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26208bf4",
   "metadata": {},
   "source": [
    "### Step 5: Execute the Agent\n",
    "Call the agent to see the full output with AI insights, RAG contexts, and tool traces.\n",
    "\n",
    "#### What to Look For\n",
    "\n",
    "When you call `run_release_readiness_agent()`, inspect:\n",
    "\n",
    "1. **Summary**: Clear and actionable overview\n",
    "2. **Gemini Insight**: AI-generated strategic assessment (when API key configured)\n",
    "3. **Recommended actions**: Priority-coded (high/medium/low)\n",
    "4. **Tool calls**: Including RAG retrieval and Gemini insight generation\n",
    "5. **RAG contexts**: Retrieved documents from FAISS\n",
    "6. **Plan**: Nested planner output\n",
    "\n",
    "#### Expected Output Structure\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"summary\": \"Curriculum Pathways targets Instructor personas...\",\n",
    "  \"gemini_insight\": \"Strategic launch assessment: The feature...\",\n",
    "  \"recommended_actions\": [\n",
    "    {\n",
    "      \"title\": \"Confirm launch communications\",\n",
    "      \"detail\": \"Share the feature brief with...\",\n",
    "      \"priority\": \"high\"\n",
    "    },\n",
    "    {\n",
    "      \"title\": \"[AI] Review documentation coverage\",\n",
    "      \"detail\": \"Gemini recommends...\",\n",
    "      \"priority\": \"medium\"\n",
    "    }\n",
    "  ],\n",
    "  \"tool_calls\": [\n",
    "    {\"tool\": \"fetch_feature_brief\", ...},\n",
    "    {\"tool\": \"rag_retrieval\", ...},\n",
    "    {\"tool\": \"gemini_insight_generation\", ...}\n",
    "  ],\n",
    "  \"rag_contexts\": [\n",
    "    {\"content\": \"...\", \"source\": \"docs/agent\", \"score\": 0.23}\n",
    "  ],\n",
    "  \"used_gemini\": true,\n",
    "  \"plan\": {...}\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2edbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from app.services.agent import AgentRunContext, run_release_readiness_agent\n",
    "from app.database import SessionLocal\n",
    "\n",
    "# Create a database session (in Docker, this connects to PostgreSQL)\n",
    "db = SessionLocal()\n",
    "\n",
    "try:\n",
    "    context = AgentRunContext(\n",
    "        feature_slug='curriculum-pathways',\n",
    "        launch_date=date(2025, 3, 10),\n",
    "        audience_role='Instructor',\n",
    "        audience_experience='intermediate',\n",
    "    )\n",
    "\n",
    "    result = run_release_readiness_agent(context, db=db)\n",
    "    \n",
    "    # Display key results\n",
    "    print(\"=== Summary ===\")\n",
    "    print(result.summary)\n",
    "    \n",
    "    print(\"\\n=== Gemini Insight ===\")\n",
    "    print(result.gemini_insight or \"(Gemini not configured)\")\n",
    "    \n",
    "    print(\"\\n=== Recommendations ===\")\n",
    "    for rec in result.recommended_actions:\n",
    "        print(f\"  [{rec.priority.upper()}] {rec.title}\")\n",
    "    \n",
    "    print(\"\\n=== Tool Calls ===\")\n",
    "    for tc in result.tool_calls:\n",
    "        print(f\"  - {tc.tool}: {tc.output_preview[:50]}...\")\n",
    "    \n",
    "    print(f\"\\n=== Used Gemini: {result.used_gemini} ===\")\n",
    "finally:\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805f56f",
   "metadata": {},
   "source": [
    "## Validation / acceptance checks\n",
    "\n",
    "### What to Verify\n",
    "\n",
    "After implementing all steps, test that:\n",
    "\n",
    "1. **The endpoint responds**: `curl` succeeds with 200 OK\n",
    "2. **The response is structured**: JSON contains `summary`, `gemini_insight`, `recommended_actions`, `plan`, `tool_calls`, `rag_contexts`, `used_gemini`\n",
    "3. **History endpoint works**: `GET /ai/history` returns past runs\n",
    "4. **Features endpoint works**: `GET /ai/features` lists available features\n",
    "5. **The documentation works**: FastAPI docs (`/docs`) show all endpoints\n",
    "6. **Error handling works**: Invalid input returns helpful error messages\n",
    "\n",
    "### Manual Testing\n",
    "\n",
    "```bash\n",
    "# Run the agent\n",
    "curl -X POST http://localhost:8000/ai/release-readiness \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\"feature_slug\":\"curriculum-pathways\",\"launch_date\":\"2025-03-10\",\"audience_role\":\"Instructor\",\"audience_experience\":\"intermediate\"}'\n",
    "\n",
    "# Get agent history\n",
    "curl http://localhost:8000/ai/history\n",
    "\n",
    "# Get available features\n",
    "curl http://localhost:8000/ai/features\n",
    "```\n",
    "\n",
    "### Expected Success Criteria\n",
    "\n",
    "- \u2705 The response includes a summary, recommendations with priorities, and tool call traces\n",
    "- \u2705 When Gemini is configured, `gemini_insight` contains AI-generated text and `used_gemini` is true\n",
    "- \u2705 The `rag_contexts` array contains retrieved documents with scores\n",
    "- \u2705 The history endpoint returns previously executed agent runs\n",
    "- \u2705 The FastAPI interactive docs (`/docs`) display all three endpoints under the **ai** tag\n",
    "- \u2705 React development mode renders the structured agent output with AI insights and RAG contexts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langchain_langsmith_future",
   "metadata": {},
   "source": [
    "## Looking Ahead: LangChain and LangSmith for Future Classes",
    "",
    "Now that you understand our agent architecture with custom tools, FAISS RAG, and Gemini integration, let's explore how industry-standard frameworks like **LangChain** and **LangSmith** could enhance and streamline this workflow in future iterations of this course.",
    "",
    "### What is LangChain?",
    "",
    "**LangChain** is an open-source framework for building applications powered by Large Language Models (LLMs). It provides abstractions and tools for:",
    "- **Chains**: Sequential operations that process inputs through multiple steps",
    "- **Agents**: Autonomous systems that decide which tools to use",
    "- **Tools**: Reusable functions that agents can call",
    "- **Memory**: Persistent context across multiple interactions",
    "- **Retrievers**: Built-in RAG and vector database integrations",
    "",
    "**Official website**: https://www.langchain.com/  ",
    "**Documentation**: https://python.langchain.com/docs/",
    "",
    "### Why LangChain Would Be Useful for Our Agent",
    "",
    "#### 1. Built-in RAG Components",
    "",
    "**What we did manually:**",
    "```python",
    "# Our custom implementation",
    "retriever = build_retriever(db)",
    "rag_contexts = retriever.search(search_query, k=3)",
    "```",
    "",
    "**With LangChain:**",
    "```python",
    "from langchain.vectorstores import FAISS",
    "from langchain.embeddings import GoogleGenerativeAIEmbeddings",
    "",
    "# More powerful, standardized",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")",
    "vectorstore = FAISS.from_documents(documents, embeddings)",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})",
    "```",
    "",
    "**Benefits:**",
    "- **Pre-built integrations** with 50+ embedding models and vector stores",
    "- **Standardized interfaces** that work across different providers",
    "- **Advanced features** like MMR (Maximal Marginal Relevance) for diversity",
    "- **Easy switching** between FAISS, Pinecone, Weaviate, Chroma, etc.",
    "",
    "#### 2. Agent Frameworks",
    "",
    "**What we did manually:**",
    "```python",
    "# Our custom agent orchestration",
    "def run_release_readiness_agent(context, db):",
    "    brief = fetch_feature_brief(context.feature_slug)",
    "    launch_window = fetch_launch_window(context.feature_slug)",
    "    rag_contexts = retriever.search(...)",
    "    gemini_insight = _generate_gemini_insight(...)",
    "    # ... manual orchestration",
    "```",
    "",
    "**With LangChain:**",
    "```python",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor",
    "from langchain.tools import tool",
    "",
    "@tool",
    "def fetch_feature_brief(feature_slug: str) -> dict:",
    "    \"\"\"Fetch feature brief for a given feature slug.\"\"\"",
    "    return {...}",
    "",
    "@tool  ",
    "def retrieve_docs(query: str) -> list[str]:",
    "    \"\"\"Retrieve relevant documentation using RAG.\"\"\"",
    "    return vectorstore.similarity_search(query, k=3)",
    "",
    "# Agent decides which tools to use and when",
    "agent = create_openai_functions_agent(llm, tools=[fetch_feature_brief, retrieve_docs])",
    "executor = AgentExecutor(agent=agent, tools=tools)",
    "result = executor.invoke({\"input\": \"Analyze release readiness for curriculum-pathways\"})",
    "```",
    "",
    "**Benefits:**",
    "- **Autonomous decision-making**: Agent chooses which tools to call",
    "- **Automatic retries**: Built-in error handling and retry logic",
    "- **Streaming**: Stream responses in real-time",
    "- **Multiple agent types**: ReAct, OpenAI Functions, Structured Chat, etc.",
    "",
    "#### 3. Prompt Templates and Chains",
    "",
    "**What we did manually:**",
    "```python",
    "prompt = f\"\"\"You are a release readiness advisor...",
    "Context:",
    "{full_context}",
    "User's Launch Date: {context.launch_date}",
    "...\"\"\"",
    "response = model.generate_content(prompt)",
    "```",
    "",
    "**With LangChain:**",
    "```python",
    "from langchain.prompts import ChatPromptTemplate",
    "from langchain.chains import LLMChain",
    "",
    "prompt = ChatPromptTemplate.from_messages([",
    "    (\"system\", \"You are a release readiness advisor helping teams prepare for launches.\"),",
    "    (\"human\", \"Based on this context: {context}\\n\\nProvide analysis for launch on {launch_date}\")",
    "])",
    "",
    "chain = LLMChain(llm=llm, prompt=prompt)",
    "result = chain.invoke({\"context\": full_context, \"launch_date\": context.launch_date})",
    "```",
    "",
    "**Benefits:**",
    "- **Reusable templates**: Define prompts once, use everywhere",
    "- **Validation**: Type-checked inputs and outputs",
    "- **Composition**: Chain multiple LLM calls together",
    "- **Few-shot examples**: Easily add example inputs/outputs",
    "",
    "#### 4. Memory Systems",
    "",
    "**What we currently have:**",
    "```python",
    "# Static: Each agent run is independent",
    "agent_run = AgentRun(...)",
    "db.add(agent_run)",
    "```",
    "",
    "**With LangChain:**",
    "```python",
    "from langchain.memory import ConversationBufferMemory",
    "",
    "# Dynamic: Agent remembers previous interactions",
    "memory = ConversationBufferMemory()",
    "chain = ConversationChain(llm=llm, memory=memory)",
    "",
    "# First call",
    "chain.invoke(\"What's the launch date for curriculum-pathways?\")",
    "",
    "# Second call remembers context",
    "chain.invoke(\"What are the risks?\")  # Knows we're still talking about curriculum-pathways",
    "```",
    "",
    "**Benefits:**",
    "- **Conversation tracking**: Multi-turn dialogues",
    "- **Context window management**: Automatic summarization",
    "- **Multiple memory types**: Buffer, summary, entity, vector store-backed",
    "",
    "### What is LangSmith?",
    "",
    "**LangSmith** is a platform for **debugging, testing, evaluating, and monitoring** LLM applications. Think of it as the observability layer for AI agents.",
    "",
    "**Official website**: https://www.langchain.com/langsmith  ",
    "**Documentation**: https://docs.smith.langchain.com/",
    "",
    "### Why LangSmith Would Be Critical for Production",
    "",
    "#### 1. Observability and Debugging",
    "",
    "**What we currently have:**",
    "```python",
    "# Limited: Just tool call traces in response",
    "tool_calls = [",
    "    AgentToolCall(tool=\"fetch_feature_brief\", ...),",
    "    AgentToolCall(tool=\"rag_retrieval\", ...),",
    "]",
    "```",
    "",
    "**With LangSmith:**",
    "- **Full trace visualization**: See every step of agent execution",
    "- **Input/output inspection**: Examine prompts and responses",
    "- **Latency breakdown**: Identify slow components",
    "- **Token usage tracking**: Monitor costs per run",
    "- **Error tracking**: Automatic error capture with context",
    "",
    "**Example trace:**",
    "```",
    "Agent Run (2.3s, $0.02)",
    "\u251c\u2500 fetch_feature_brief (0.1s)",
    "\u2502  \u2514\u2500 Input: {\"feature_slug\": \"curriculum-pathways\"}",
    "\u2502  \u2514\u2500 Output: {\"name\": \"Curriculum Pathways\", ...}",
    "\u251c\u2500 RAG retrieval (0.4s)",
    "\u2502  \u251c\u2500 Embedding (0.1s, 5 tokens)",
    "\u2502  \u2514\u2500 FAISS search (0.3s)",
    "\u2502  \u2514\u2500 Output: [3 documents]",
    "\u251c\u2500 Gemini insight (1.8s, $0.02)",
    "\u2502  \u251c\u2500 Prompt (234 tokens)",
    "\u2502  \u251c\u2500 Response (156 tokens)",
    "\u2502  \u2514\u2500 Output: \"Strategic launch assessment...\"",
    "\u2514\u2500 Result assembled (0.0s)",
    "```",
    "",
    "#### 2. Dataset Management and Testing",
    "",
    "**What we currently lack:**",
    "```python",
    "# Manual testing, no test suite",
    "# Have to run agent manually to verify behavior",
    "```",
    "",
    "**With LangSmith:**",
    "```python",
    "# Create datasets for evaluation",
    "dataset = client.create_dataset(\"release_readiness_tests\")",
    "",
    "# Add test cases",
    "client.create_examples(",
    "    dataset_id=dataset.id,",
    "    inputs=[",
    "        {\"feature_slug\": \"curriculum-pathways\", \"launch_date\": \"2025-03-01\"},",
    "        {\"feature_slug\": \"ai-code-review\", \"launch_date\": \"2025-04-15\"},",
    "    ],",
    "    outputs=[",
    "        {\"expected_recommendations\": [\"Confirm launch communications\", ...]},",
    "        {\"expected_recommendations\": [\"Validate operational readiness\", ...]},",
    "    ]",
    ")",
    "",
    "# Run evaluation",
    "results = client.run_on_dataset(",
    "    dataset_name=\"release_readiness_tests\",",
    "    llm_or_chain=agent_chain,",
    "    evaluation=custom_evaluator",
    ")",
    "```",
    "",
    "**Benefits:**",
    "- **Regression testing**: Ensure changes don't break existing behavior",
    "- **A/B testing**: Compare different prompts or models",
    "- **Ground truth comparison**: Measure accuracy against expected outputs",
    "",
    "#### 3. Prompt Iteration and Optimization",
    "",
    "**What we currently do:**",
    "```python",
    "# Manual: Edit prompt string, redeploy, test manually",
    "prompt = f\"You are a release readiness advisor...\"",
    "```",
    "",
    "**With LangSmith:**",
    "- **Prompt playground**: Test prompts interactively",
    "- **Version control**: Track prompt changes over time",
    "- **Comparison view**: See outputs side-by-side",
    "- **Automatic optimization**: Find best-performing prompt variants",
    "",
    "#### 4. Production Monitoring",
    "",
    "**What we currently have:**",
    "```python",
    "# Basic: Save runs to database",
    "agent_run = AgentRun(...)",
    "db.add(agent_run)",
    "```",
    "",
    "**With LangSmith:**",
    "- **Real-time dashboards**: Monitor agent performance live",
    "- **Alerting**: Get notified of errors or anomalies",
    "- **Cost tracking**: See token usage and costs per endpoint",
    "- **User feedback**: Collect thumbs up/down from users",
    "- **Automated analysis**: Identify patterns in failures",
    "",
    "### Migration Path: From Our Implementation to LangChain",
    "",
    "If we were to adopt LangChain in future classes, here's how we'd migrate:",
    "",
    "#### Phase 1: RAG Layer (Easiest)",
    "```python",
    "# Replace app/services/rag.py with LangChain vectorstore",
    "from langchain.vectorstores import FAISS",
    "from langchain.embeddings import GoogleGenerativeAIEmbeddings",
    "",
    "vectorstore = FAISS.from_documents(chunks, GoogleGenerativeAIEmbeddings())",
    "```",
    "",
    "#### Phase 2: Tool Definitions",
    "```python",
    "# Convert app/services/agent_tools.py to LangChain tools",
    "from langchain.tools import tool",
    "",
    "@tool",
    "def fetch_feature_brief(feature_slug: str) -> FeatureBrief:",
    "    \"\"\"Fetch feature brief for release planning.\"\"\"",
    "    return FeatureBrief(...)",
    "```",
    "",
    "#### Phase 3: Agent Logic",
    "```python",
    "# Replace app/services/agent.py with LangChain agent",
    "from langchain.agents import create_openai_functions_agent",
    "",
    "agent = create_openai_functions_agent(",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\"),",
    "    tools=[fetch_feature_brief, fetch_launch_window, retrieve_docs],",
    "    prompt=prompt_template",
    ")",
    "```",
    "",
    "#### Phase 4: Add LangSmith",
    "```python",
    "import os",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"your-key\"",
    "",
    "# That's it! All runs now traced automatically",
    "```",
    "",
    "### When to Use LangChain vs Custom Implementation",
    "",
    "**Use custom implementation (like ours) when:**",
    "- \u2705 Learning fundamentals (educational context)",
    "- \u2705 Full control over every detail",
    "- \u2705 Minimal dependencies",
    "- \u2705 Simple, deterministic workflows",
    "- \u2705 Offline operation required",
    "",
    "**Use LangChain when:**",
    "- \u2705 Building production systems",
    "- \u2705 Need to iterate quickly on prompts",
    "- \u2705 Want built-in observability",
    "- \u2705 Need to support multiple LLM providers",
    "- \u2705 Complex agent orchestration",
    "- \u2705 Team collaboration on prompts",
    "",
    "### Hands-on Exercise for Future Classes",
    "",
    "**Goal**: Convert one part of our agent to use LangChain",
    "",
    "1. **Install LangChain**: `pip install langchain langchain-google-genai`",
    "2. **Replace RAG**: Use `langchain.vectorstores.FAISS` instead of our custom `rag.py`",
    "3. **Add tracing**: Enable LangSmith to visualize agent execution",
    "4. **Compare**: Measure performance, code complexity, and developer experience",
    "",
    "### Resources for Deeper Learning",
    "",
    "**LangChain:**",
    "- \ud83d\udcd8 **Official Docs**: https://python.langchain.com/docs/",
    "- \ud83c\udf93 **Tutorials**: https://python.langchain.com/docs/tutorials/",
    "- \ud83d\udce6 **Agent Templates**: https://python.langchain.com/docs/modules/agents/",
    "- \ud83d\udcac **Community**: Discord and GitHub discussions",
    "",
    "**LangSmith:**",
    "- \ud83d\udcd8 **Docs**: https://docs.smith.langchain.com/",
    "- \ud83c\udfa5 **Demo Videos**: https://www.langchain.com/langsmith",
    "- \ud83d\udcca **Evaluation Guide**: https://docs.smith.langchain.com/evaluation",
    "- \ud83d\udd0d **Tracing Guide**: https://docs.smith.langchain.com/tracing",
    "",
    "### Key Takeaways",
    "",
    "1. **Our implementation taught you the fundamentals** - You now understand:",
    "   - How embeddings work",
    "   - How FAISS indexes documents",
    "   - How RAG retrieves context",
    "   - How agents orchestrate tools",
    "   - How to structure AI applications",
    "",
    "2. **LangChain provides production-ready abstractions** - It handles:",
    "   - Provider integrations (Gemini, OpenAI, Anthropic, etc.)",
    "   - Prompt management and versioning",
    "   - Agent frameworks and tooling",
    "   - Error handling and retries",
    "",
    "3. **LangSmith enables production monitoring** - Essential for:",
    "   - Debugging complex agent behavior",
    "   - Evaluating prompt changes",
    "   - Tracking costs and latency",
    "   - Collecting user feedback",
    "",
    "4. **The choice depends on your context**:",
    "   - **Learning/Teaching**: Custom implementation (better understanding)",
    "   - **Production**: LangChain + LangSmith (faster iteration, better tooling)",
    "   - **Hybrid**: Start custom, migrate to LangChain as complexity grows",
    "",
    "By understanding both approaches, you're equipped to:",
    "- Build AI agents from first principles",
    "- Adopt industry-standard frameworks when appropriate",
    "- Make informed architectural decisions",
    "- Debug and optimize agent behavior",
    "- Scale from prototype to production",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b83fcb",
   "metadata": {},
   "source": [
    "## Homework / extensions\n",
    "\n",
    "The current implementation already includes what were previously extension challenges:\n",
    "- \u2705 **Gemini AI integration** for generating strategic insights\n",
    "- \u2705 **FAISS RAG** for retrieving relevant documentation\n",
    "- \u2705 **Database persistence** for auditing agent runs\n",
    "- \u2705 **Priority levels** for recommendations\n",
    "- \u2705 **Frontend integration** with the AgentPanel component\n",
    "\n",
    "### New Extension Ideas\n",
    "\n",
    "1. **Add more sophisticated prompting**\n",
    "   - Implement few-shot examples in Gemini prompts\n",
    "   - Add chain-of-thought reasoning\n",
    "   - *Teaching moment*: Prompt engineering for production systems\n",
    "\n",
    "2. **Implement agent memory**\n",
    "   - Use past runs to inform new recommendations\n",
    "   - Track feature launch patterns over time\n",
    "   - *Teaching moment*: Stateful agents and learning from history\n",
    "\n",
    "3. **Add real-time streaming**\n",
    "   - Stream Gemini responses to the frontend\n",
    "   - Show progressive tool call results\n",
    "   - *Teaching moment*: Server-sent events and async patterns\n",
    "\n",
    "4. **Create an agent evaluation framework**\n",
    "   - Define test cases with expected recommendations\n",
    "   - Measure recommendation quality over time\n",
    "   - *Teaching moment*: Evaluating AI systems\n",
    "\n",
    "5. **Add multi-agent orchestration**\n",
    "   - Create specialized sub-agents for different concerns\n",
    "   - Implement agent-to-agent communication\n",
    "   - *Teaching moment*: Multi-agent architectures\n",
    "\n",
    "### Advanced Challenges\n",
    "\n",
    "- **Implement semantic caching** to avoid repeated RAG queries\n",
    "- **Add confidence scores** to recommendations\n",
    "- **Create a feedback loop** where users rate recommendations\n",
    "- **Implement A/B testing** for different prompting strategies\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
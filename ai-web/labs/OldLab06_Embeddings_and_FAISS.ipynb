{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35143631",
   "metadata": {},
   "source": [
    "## Looking Ahead: LangChain and LangSmith for Future Classes\n",
    "\n",
    "Now that you understand our agent architecture with custom tools, FAISS RAG, and Gemini integration, let's explore how industry-standard frameworks like **LangChain** and **LangSmith** could enhance and streamline this workflow in future iterations of this course.\n",
    "\n",
    "### What is LangChain?\n",
    "\n",
    "**LangChain** is an open-source framework for building applications powered by Large Language Models (LLMs). It provides abstractions and tools for:\n",
    "- **Chains**: Sequential operations that process inputs through multiple steps\n",
    "- **Agents**: Autonomous systems that decide which tools to use\n",
    "- **Tools**: Reusable functions that agents can call\n",
    "- **Memory**: Persistent context across multiple interactions\n",
    "- **Retrievers**: Built-in RAG and vector database integrations\n",
    "\n",
    "**Official website**: https://www.langchain.com/  \n",
    "**Documentation**: https://python.langchain.com/docs/\n",
    "\n",
    "### Why LangChain Would Be Useful for Our Agent\n",
    "\n",
    "#### 1. Built-in RAG Components\n",
    "\n",
    "**What we did manually:**\n",
    "```python\n",
    "# Our custom implementation\n",
    "retriever = build_retriever(db)\n",
    "rag_contexts = retriever.search(search_query, k=3)\n",
    "```\n",
    "\n",
    "**With LangChain:**\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# More powerful, standardized\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- **Pre-built integrations** with 50+ embedding models and vector stores\n",
    "- **Standardized interfaces** that work across different providers\n",
    "- **Advanced features** like MMR (Maximal Marginal Relevance) for diversity\n",
    "- **Easy switching** between FAISS, Pinecone, Weaviate, Chroma, etc.\n",
    "\n",
    "#### 2. Agent Frameworks\n",
    "\n",
    "**What we did manually:**\n",
    "```python\n",
    "# Our custom agent orchestration\n",
    "def run_release_readiness_agent(context, db):\n",
    "    brief = fetch_feature_brief(context.feature_slug)\n",
    "    launch_window = fetch_launch_window(context.feature_slug)\n",
    "    rag_contexts = retriever.search(...)\n",
    "    gemini_insight = _generate_gemini_insight(...)\n",
    "    # ... manual orchestration\n",
    "```\n",
    "\n",
    "**With LangChain:**\n",
    "```python\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def fetch_feature_brief(feature_slug: str) -> dict:\n",
    "    \"\"\"Fetch feature brief for a given feature slug.\"\"\"\n",
    "    return {...}\n",
    "\n",
    "@tool  \n",
    "def retrieve_docs(query: str) -> list[str]:\n",
    "    \"\"\"Retrieve relevant documentation using RAG.\"\"\"\n",
    "    return vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "# Agent decides which tools to use and when\n",
    "agent = create_openai_functions_agent(llm, tools=[fetch_feature_brief, retrieve_docs])\n",
    "executor = AgentExecutor(agent=agent, tools=tools)\n",
    "result = executor.invoke({\"input\": \"Analyze release readiness for curriculum-pathways\"})\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- **Autonomous decision-making**: Agent chooses which tools to call\n",
    "- **Automatic retries**: Built-in error handling and retry logic\n",
    "- **Streaming**: Stream responses in real-time\n",
    "- **Multiple agent types**: ReAct, OpenAI Functions, Structured Chat, etc.\n",
    "\n",
    "#### 3. Prompt Templates and Chains\n",
    "\n",
    "**What we did manually:**\n",
    "```python\n",
    "prompt = f\"\"\"You are a release readiness advisor...\n",
    "Context:\n",
    "{full_context}\n",
    "User's Launch Date: {context.launch_date}\n",
    "...\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "```\n",
    "\n",
    "**With LangChain:**\n",
    "```python\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a release readiness advisor helping teams prepare for launches.\"),\n",
    "    (\"human\", \"Based on this context: {context}\\n\\nProvide analysis for launch on {launch_date}\")\n",
    "])\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "result = chain.invoke({\"context\": full_context, \"launch_date\": context.launch_date})\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- **Reusable templates**: Define prompts once, use everywhere\n",
    "- **Validation**: Type-checked inputs and outputs\n",
    "- **Composition**: Chain multiple LLM calls together\n",
    "- **Few-shot examples**: Easily add example inputs/outputs\n",
    "\n",
    "#### 4. Memory Systems\n",
    "\n",
    "**What we currently have:**\n",
    "```python\n",
    "# Static: Each agent run is independent\n",
    "agent_run = AgentRun(...)\n",
    "db.add(agent_run)\n",
    "```\n",
    "\n",
    "**With LangChain:**\n",
    "```python\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Dynamic: Agent remembers previous interactions\n",
    "memory = ConversationBufferMemory()\n",
    "chain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "# First call\n",
    "chain.invoke(\"What's the launch date for curriculum-pathways?\")\n",
    "\n",
    "# Second call remembers context\n",
    "chain.invoke(\"What are the risks?\")  # Knows we're still talking about curriculum-pathways\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- **Conversation tracking**: Multi-turn dialogues\n",
    "- **Context window management**: Automatic summarization\n",
    "- **Multiple memory types**: Buffer, summary, entity, vector store-backed\n",
    "\n",
    "### What is LangSmith?\n",
    "\n",
    "**LangSmith** is a platform for **debugging, testing, evaluating, and monitoring** LLM applications. Think of it as the observability layer for AI agents.\n",
    "\n",
    "**Official website**: https://www.langchain.com/langsmith  \n",
    "**Documentation**: https://docs.smith.langchain.com/\n",
    "\n",
    "### Why LangSmith Would Be Critical for Production\n",
    "\n",
    "#### 1. Observability and Debugging\n",
    "\n",
    "**What we currently have:**\n",
    "```python\n",
    "# Limited: Just tool call traces in response\n",
    "tool_calls = [\n",
    "    AgentToolCall(tool=\"fetch_feature_brief\", ...),\n",
    "    AgentToolCall(tool=\"rag_retrieval\", ...),\n",
    "]\n",
    "```\n",
    "\n",
    "**With LangSmith:**\n",
    "- **Full trace visualization**: See every step of agent execution\n",
    "- **Input/output inspection**: Examine prompts and responses\n",
    "- **Latency breakdown**: Identify slow components\n",
    "- **Token usage tracking**: Monitor costs per run\n",
    "- **Error tracking**: Automatic error capture with context\n",
    "\n",
    "**Example trace:**\n",
    "```\n",
    "Agent Run (2.3s, $0.02)\n",
    "â”œâ”€ fetch_feature_brief (0.1s)\n",
    "â”‚  â””â”€ Input: {\"feature_slug\": \"curriculum-pathways\"}\n",
    "â”‚  â””â”€ Output: {\"name\": \"Curriculum Pathways\", ...}\n",
    "â”œâ”€ RAG retrieval (0.4s)\n",
    "â”‚  â”œâ”€ Embedding (0.1s, 5 tokens)\n",
    "â”‚  â””â”€ FAISS search (0.3s)\n",
    "â”‚  â””â”€ Output: [3 documents]\n",
    "â”œâ”€ Gemini insight (1.8s, $0.02)\n",
    "â”‚  â”œâ”€ Prompt (234 tokens)\n",
    "â”‚  â”œâ”€ Response (156 tokens)\n",
    "â”‚  â””â”€ Output: \"Strategic launch assessment...\"\n",
    "â””â”€ Result assembled (0.0s)\n",
    "```\n",
    "\n",
    "#### 2. Dataset Management and Testing\n",
    "\n",
    "**What we currently lack:**\n",
    "```python\n",
    "# Manual testing, no test suite\n",
    "# Have to run agent manually to verify behavior\n",
    "```\n",
    "\n",
    "**With LangSmith:**\n",
    "```python\n",
    "# Create datasets for evaluation\n",
    "dataset = client.create_dataset(\"release_readiness_tests\")\n",
    "\n",
    "# Add test cases\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    inputs=[\n",
    "        {\"feature_slug\": \"curriculum-pathways\", \"launch_date\": \"2025-03-01\"},\n",
    "        {\"feature_slug\": \"ai-code-review\", \"launch_date\": \"2025-04-15\"},\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"expected_recommendations\": [\"Confirm launch communications\", ...]},\n",
    "        {\"expected_recommendations\": [\"Validate operational readiness\", ...]},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "results = client.run_on_dataset(\n",
    "    dataset_name=\"release_readiness_tests\",\n",
    "    llm_or_chain=agent_chain,\n",
    "    evaluation=custom_evaluator\n",
    ")\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- **Regression testing**: Ensure changes don't break existing behavior\n",
    "- **A/B testing**: Compare different prompts or models\n",
    "- **Ground truth comparison**: Measure accuracy against expected outputs\n",
    "\n",
    "#### 3. Prompt Iteration and Optimization\n",
    "\n",
    "**What we currently do:**\n",
    "```python\n",
    "# Manual: Edit prompt string, redeploy, test manually\n",
    "prompt = f\"You are a release readiness advisor...\"\n",
    "```\n",
    "\n",
    "**With LangSmith:**\n",
    "- **Prompt playground**: Test prompts interactively\n",
    "- **Version control**: Track prompt changes over time\n",
    "- **Comparison view**: See outputs side-by-side\n",
    "- **Automatic optimization**: Find best-performing prompt variants\n",
    "\n",
    "#### 4. Production Monitoring\n",
    "\n",
    "**What we currently have:**\n",
    "```python\n",
    "# Basic: Save runs to database\n",
    "agent_run = AgentRun(...)\n",
    "db.add(agent_run)\n",
    "```\n",
    "\n",
    "**With LangSmith:**\n",
    "- **Real-time dashboards**: Monitor agent performance live\n",
    "- **Alerting**: Get notified of errors or anomalies\n",
    "- **Cost tracking**: See token usage and costs per endpoint\n",
    "- **User feedback**: Collect thumbs up/down from users\n",
    "- **Automated analysis**: Identify patterns in failures\n",
    "\n",
    "### Migration Path: From Our Implementation to LangChain\n",
    "\n",
    "If we were to adopt LangChain in future classes, here's how we'd migrate:\n",
    "\n",
    "#### Phase 1: RAG Layer (Easiest)\n",
    "```python\n",
    "# Replace app/services/rag.py with LangChain vectorstore\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, GoogleGenerativeAIEmbeddings())\n",
    "```\n",
    "\n",
    "#### Phase 2: Tool Definitions\n",
    "```python\n",
    "# Convert app/services/agent_tools.py to LangChain tools\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def fetch_feature_brief(feature_slug: str) -> FeatureBrief:\n",
    "    \"\"\"Fetch feature brief for release planning.\"\"\"\n",
    "    return FeatureBrief(...)\n",
    "```\n",
    "\n",
    "#### Phase 3: Agent Logic\n",
    "```python\n",
    "# Replace app/services/agent.py with LangChain agent\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(\n",
    "    llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\"),\n",
    "    tools=[fetch_feature_brief, fetch_launch_window, retrieve_docs],\n",
    "    prompt=prompt_template\n",
    ")\n",
    "```\n",
    "\n",
    "#### Phase 4: Add LangSmith\n",
    "```python\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"your-key\"\n",
    "\n",
    "# That's it! All runs now traced automatically\n",
    "```\n",
    "\n",
    "### When to Use LangChain vs Custom Implementation\n",
    "\n",
    "**Use custom implementation (like ours) when:**\n",
    "- âœ… Learning fundamentals (educational context)\n",
    "- âœ… Full control over every detail\n",
    "- âœ… Minimal dependencies\n",
    "- âœ… Simple, deterministic workflows\n",
    "- âœ… Offline operation required\n",
    "\n",
    "**Use LangChain when:**\n",
    "- âœ… Building production systems\n",
    "- âœ… Need to iterate quickly on prompts\n",
    "- âœ… Want built-in observability\n",
    "- âœ… Need to support multiple LLM providers\n",
    "- âœ… Complex agent orchestration\n",
    "- âœ… Team collaboration on prompts\n",
    "\n",
    "### Hands-on Exercise for Future Classes\n",
    "\n",
    "**Goal**: Convert one part of our agent to use LangChain\n",
    "\n",
    "1. **Install LangChain**: `pip install langchain langchain-google-genai`\n",
    "2. **Replace RAG**: Use `langchain.vectorstores.FAISS` instead of our custom `rag.py`\n",
    "3. **Add tracing**: Enable LangSmith to visualize agent execution\n",
    "4. **Compare**: Measure performance, code complexity, and developer experience\n",
    "\n",
    "### Resources for Deeper Learning\n",
    "\n",
    "**LangChain:**\n",
    "- ðŸ“˜ **Official Docs**: https://python.langchain.com/docs/\n",
    "- ðŸŽ“ **Tutorials**: https://python.langchain.com/docs/tutorials/\n",
    "- ðŸ“¦ **Agent Templates**: https://python.langchain.com/docs/modules/agents/\n",
    "- ðŸ’¬ **Community**: Discord and GitHub discussions\n",
    "\n",
    "**LangSmith:**\n",
    "- ðŸ“˜ **Docs**: https://docs.smith.langchain.com/\n",
    "- ðŸŽ¥ **Demo Videos**: https://www.langchain.com/langsmith\n",
    "- ðŸ“Š **Evaluation Guide**: https://docs.smith.langchain.com/evaluation\n",
    "- ðŸ” **Tracing Guide**: https://docs.smith.langchain.com/tracing\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Our implementation taught you the fundamentals** - You now understand:\n",
    "   - How embeddings work\n",
    "   - How FAISS indexes documents\n",
    "   - How RAG retrieves context\n",
    "   - How agents orchestrate tools\n",
    "   - How to structure AI applications\n",
    "\n",
    "2. **LangChain provides production-ready abstractions** - It handles:\n",
    "   - Provider integrations (Gemini, OpenAI, Anthropic, etc.)\n",
    "   - Prompt management and versioning\n",
    "   - Agent frameworks and tooling\n",
    "   - Error handling and retries\n",
    "\n",
    "3. **LangSmith enables production monitoring** - Essential for:\n",
    "   - Debugging complex agent behavior\n",
    "   - Evaluating prompt changes\n",
    "   - Tracking costs and latency\n",
    "   - Collecting user feedback\n",
    "\n",
    "4. **The choice depends on your context**:\n",
    "   - **Learning/Teaching**: Custom implementation (better understanding)\n",
    "   - **Production**: LangChain + LangSmith (faster iteration, better tooling)\n",
    "   - **Hybrid**: Start custom, migrate to LangChain as complexity grows\n",
    "\n",
    "By understanding both approaches, you're equipped to:\n",
    "- Build AI agents from first principles\n",
    "- Adopt industry-standard frameworks when appropriate\n",
    "- Make informed architectural decisions\n",
    "- Debug and optimize agent behavior\n",
    "- Scale from prototype to production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1be625",
   "metadata": {},
   "source": [
    "## Homework / extensions\n",
    "\n",
    "The current implementation already includes what were previously extension challenges:\n",
    "- âœ… **Gemini AI integration** for generating strategic insights\n",
    "- âœ… **FAISS RAG** for retrieving relevant documentation\n",
    "- âœ… **Database persistence** for auditing agent runs\n",
    "- âœ… **Priority levels** for recommendations\n",
    "- âœ… **Frontend integration** with the AgentPanel component\n",
    "\n",
    "### New Extension Ideas\n",
    "\n",
    "1. **Add more sophisticated prompting**\n",
    "   - Implement few-shot examples in Gemini prompts\n",
    "   - Add chain-of-thought reasoning\n",
    "   - *Teaching moment*: Prompt engineering for production systems\n",
    "\n",
    "2. **Implement agent memory**\n",
    "   - Use past runs to inform new recommendations\n",
    "   - Track feature launch patterns over time\n",
    "   - *Teaching moment*: Stateful agents and learning from history\n",
    "\n",
    "3. **Add real-time streaming**\n",
    "   - Stream Gemini responses to the frontend\n",
    "   - Show progressive tool call results\n",
    "   - *Teaching moment*: Server-sent events and async patterns\n",
    "\n",
    "4. **Create an agent evaluation framework**\n",
    "   - Define test cases with expected recommendations\n",
    "   - Measure recommendation quality over time\n",
    "   - *Teaching moment*: Evaluating AI systems\n",
    "\n",
    "5. **Add multi-agent orchestration**\n",
    "   - Create specialized sub-agents for different concerns\n",
    "   - Implement agent-to-agent communication\n",
    "   - *Teaching moment*: Multi-agent architectures\n",
    "\n",
    "### Advanced Challenges\n",
    "\n",
    "- **Implement semantic caching** to avoid repeated RAG queries\n",
    "- **Add confidence scores** to recommendations\n",
    "- **Create a feedback loop** where users rate recommendations\n",
    "- **Implement A/B testing** for different prompting strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23498c17",
   "metadata": {},
   "source": [
    "# Lab 06 Â· Embeddings and FAISS\n",
    "\n",
    "*This lab notebook provides guided steps. All commands are intended for local execution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1e166",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Document chunking routines are introduced.\n",
    "- The \"text-embedding-004\" vectors are stored in a FAISS index.\n",
    "- A search endpoint returns top results with scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451f2b6",
   "metadata": {},
   "source": [
    "## What will be learned\n",
    "- Document preprocessing for embeddings is rehearsed.\n",
    "- FAISS index persistence is described.\n",
    "- Vector search endpoints are surfaced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d6bc2d",
   "metadata": {},
   "source": [
    "## Prerequisites & install\n",
    "The following commands are intended for local execution.\n",
    "\n",
    "```bash\n",
    "cd ai-web/backend\n",
    ". .venv/bin/activate\n",
    "pip install faiss-cpu google-generativeai numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da0e81",
   "metadata": {},
   "source": [
    "## Step-by-step tasks\n",
    "### Step 1: Chunking utility\n",
    "A chunking helper is added so documents are segmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "vector_path = Path(\"ai-web/backend/app/vector.py\")\n",
    "vector_path.write_text('''import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "from google import genai\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "\n",
    "DATA_DIR = Path(__file__).resolve().parent / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INDEX_FILE = DATA_DIR / \"embeddings.index\"\n",
    "META_FILE = DATA_DIR / \"metadata.json\"\n",
    "\n",
    "\n",
    "def _client() -> genai.Client:\n",
    "  api_key = os.environ.get('GEMINI_API_KEY', '')\n",
    "  if not api_key:\n",
    "    raise RuntimeError('A backend API key is required for embeddings.')\n",
    "  return genai.Client(api_key=api_key)\n",
    "\n",
    "\n",
    "def _text_content(text: str) -> dict:\n",
    "  return {\"parts\": [{\"text\": text}]}\n",
    "\n",
    "\n",
    "def chunk_text(text: str, size: int = 400) -> List[str]:\n",
    "  return [text[i:i + size] for i in range(0, len(text), size) if text[i:i + size].strip()]\n",
    "\n",
    "\n",
    "def embed_chunks(chunks: List[str]) -> np.ndarray:\n",
    "  client = _client()\n",
    "  response = client.models.embed_content(\n",
    "      model='text-embedding-004',\n",
    "      contents=[_text_content(chunk) for chunk in chunks],\n",
    "  )\n",
    "  embeddings = response.embeddings or []\n",
    "  if not embeddings:\n",
    "    raise RuntimeError('No embeddings were returned from the Gemini API.')\n",
    "  return np.array([item.values for item in embeddings], dtype=np.float32)\n",
    "\n",
    "\n",
    "def save_index(chunks: List[str], vectors: np.ndarray) -> None:\n",
    "  index = faiss.IndexFlatIP(vectors.shape[1])\n",
    "  faiss.normalize_L2(vectors)\n",
    "  index.add(vectors)\n",
    "  faiss.write_index(index, str(INDEX_FILE))\n",
    "  META_FILE.write_text(json.dumps({\"chunks\": chunks}))\n",
    "\n",
    "\n",
    "def load_index() -> Tuple[faiss.Index, List[str]]:\n",
    "  index = faiss.read_index(str(INDEX_FILE))\n",
    "  chunks = json.loads(META_FILE.read_text())[\"chunks\"]\n",
    "  return index, chunks\n",
    "\n",
    "\n",
    "def search(query: str, top_k: int = 3) -> List[Tuple[str, float]]:\n",
    "  index, chunks = load_index()\n",
    "  query_vec = embed_chunks([query])\n",
    "  faiss.normalize_L2(query_vec)\n",
    "  scores, neighbors = index.search(query_vec, top_k)\n",
    "  return [(chunks[i], float(scores[0][pos])) for pos, i in enumerate(neighbors[0])]\n",
    "''')\n",
    "print(\"Vector helper was written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f5f29",
   "metadata": {},
   "source": [
    "### Step 2: Index builder cell\n",
    "An index is created from a small sample document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f14a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('ai-web/backend')))\n",
    "from app.vector import chunk_text, embed_chunks, save_index\n",
    "\n",
    "sample_text = \"\"\"This course demonstrates AI in web programming.\n",
    "The backend relies on FastAPI and Gemini proxies.\n",
    "Vector search provides relevant snippets.\n",
    "\"\"\"\n",
    "chunks = chunk_text(sample_text)\n",
    "vectors = embed_chunks(chunks)\n",
    "save_index(chunks, vectors)\n",
    "print('Index was generated with', len(chunks), 'chunks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1be89",
   "metadata": {},
   "source": [
    "### Step 3: Search endpoint\n",
    "A FastAPI endpoint is published for vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "main_path = Path(\"ai-web/backend/app/main.py\")\n",
    "text = main_path.read_text()\n",
    "if \"search_endpoint\" not in text:\n",
    "    addition = '''\n",
    "from typing import Optional\n",
    "from .vector import search\n",
    "\n",
    "\n",
    "@app.get(\"/api/search\")\n",
    "def search_endpoint(q: str, k: Optional[int] = 3):\n",
    "    results = search(q, int(k))\n",
    "    return {\"results\": [{\"text\": text, \"score\": score} for text, score in results]}\n",
    "'''\n",
    "    main_path.write_text(text.rstrip() + \"\n",
    "\" + addition)\n",
    "    print(\"Search endpoint was appended.\")\n",
    "else:\n",
    "    print(\"Search endpoint already present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c0e0d",
   "metadata": {},
   "source": [
    "## Validation / acceptance checks\n",
    "```bash\n",
    "# locally\n",
    "curl 'http://localhost:8000/api/search?q=fastapi&k=2'\n",
    "```\n",
    "- A JSON response containing scored chunks is observed.\n",
    "- React development mode shows the described UI state without console errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe9259",
   "metadata": {},
   "source": [
    "## Homework / extensions\n",
    "- Periodic index rebuild strategies are evaluated for large document sets.\n",
    "- Client-side rendering of search results is explored."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

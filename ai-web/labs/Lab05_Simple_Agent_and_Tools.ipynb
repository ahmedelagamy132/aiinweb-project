{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c2cc28",
   "metadata": {},
   "source": [
    "# Lab 05 \u00b7 Release Readiness Agent and Tools\n",
    "\n",
    "*This lab notebook provides guided steps. All commands are intended for local execution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15651818",
   "metadata": {},
   "source": [
    "## Objectives\n- Model a deterministic release readiness agent that can plug into the existing AI web app.\n- Provide credible tool abstractions for product briefs, launch windows, and stakeholder contacts.\n- Expose an `/ai/release-readiness` endpoint that returns structured recommendations and planner output.\n\nIn this lab, you will build a **deterministic release readiness agent** that demonstrates the core concepts of AI agent architecture:\n\n1. **Model an agent workflow**: Learn how agents orchestrate multiple tools to accomplish complex tasks\n2. **Build tool abstractions**: Create reusable functions that agents can call to gather information\n3. **Structure agent responses**: Return well-formatted JSON that frontend applications can easily consume\n4. **Integrate with existing APIs**: Expose your agent through FastAPI endpoints\n\nThis lab focuses on a **deterministic agent** (no LLM required) to help you understand the fundamental architecture before adding AI capabilities in future labs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da98749",
   "metadata": {},
   "source": [
    "## What will be learned\n- Coordinating multiple service helpers inside an agent workflow.\n- Returning Pydantic models that the frontend can render without extra parsing.\n- Logging tool invocations to aid observability and debugging.\n\nBy the end of this lab, you will understand:\n\n### Core Concepts\n- **Agent Architecture**: How agents break down complex tasks into smaller tool calls\n- **Tool Design**: Creating focused functions that do one thing well\n- **Service Layer Pattern**: Separating business logic from API routing\n- **Structured Output**: Using Pydantic models for type-safe responses\n\n### Technical Skills\n- **Coordinating service helpers**: Calling multiple functions within an agent workflow\n- **Pydantic models**: Defining schemas that validate data and generate documentation\n- **Error handling**: Gracefully managing missing data or invalid inputs\n- **Logging tool invocations**: Tracking which tools were called and what they returned\n\n### Teaching Moments\n- Why deterministic agents are easier to debug than LLM-based agents\n- How tool outputs compose into a coherent agent response\n- Best practices for structuring multi-step workflows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32b18c2",
   "metadata": {},
   "source": [
    "## Prerequisites & install\nReuse the virtual environment created earlier in the course. No additional dependencies are required beyond `pydantic`.\n\n```bash\ncd ai-web/backend\n. .venv/bin/activate\npip install pydantic\n```\n\n### Environment Setup\nReuse the virtual environment created earlier in the course. This lab builds on the FastAPI foundation from previous labs.\n\n### Required Dependencies\nOnly `pydantic` is needed beyond the base FastAPI installation. Pydantic provides:\n- Data validation\n- Type hints and IDE support\n- Automatic JSON serialization\n- Interactive API documentation\n\n```bash\ncd ai-web/backend\n. .venv/bin/activate\npip install pydantic\n```\n\n### Verification\nEnsure your backend is running and accessible:\n```bash\ncurl http://localhost:8000/health\n```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ada4db",
   "metadata": {},
   "source": [
    "## Step-by-step tasks\nBuild out the tools, service, and router layers needed to run the release readiness agent.\n\n### Architecture Overview\n\nBefore diving into code, let's understand the three-layer architecture we'll build:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FastAPI Router (agent.py)             \u2502  \u2190 HTTP endpoints\n\u2502  - Receives requests                    \u2502\n\u2502  - Validates input                      \u2502\n\u2502  - Returns JSON responses               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Agent Service (agent.py)               \u2502  \u2190 Business logic\n\u2502  - Orchestrates tool calls              \u2502\n\u2502  - Builds recommendations               \u2502\n\u2502  - Structures output                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tools (agent_tools.py)                 \u2502  \u2190 Data sources\n\u2502  - fetch_feature_brief()                \u2502\n\u2502  - fetch_launch_window()                \u2502\n\u2502  - fetch_support_contacts()             \u2502\n\u2502  - list_slo_watch_items()               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis separation of concerns makes the system:\n- **Testable**: Each layer can be tested independently\n- **Maintainable**: Changes to one layer don't ripple through the entire system\n- **Reusable**: Tools can be used by multiple agents\n\nLet's build each layer from the bottom up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa103e09",
   "metadata": {},
   "source": [
    "### Step 1: Release data tools\nCapture deterministic product data in `app/services/agent_tools.py` so the agent can make realistic decisions.\n\n#### What Are Tools?\nTools are **focused functions** that agents call to gather information or perform actions. Each tool should:\n- Do **one thing well**\n- Have **clear inputs and outputs**\n- Be **stateless** (no hidden dependencies)\n- Return **structured data** (Pydantic models, not raw dicts)\n\n#### Why Use Tools?\n- **Modularity**: Tools can be reused across multiple agents\n- **Testing**: Easy to test in isolation with mock data\n- **Traceability**: Log which tools were called and what they returned\n- **Swappability**: Replace mock data with real API calls later\n\n#### What We're Building\nWe'll create four tools that provide product release data:\n\n1. **`fetch_feature_brief(feature_slug)`**: Returns product information\n   - Who is it for?\n   - What does it do?\n   - How do we measure success?\n\n2. **`fetch_launch_window(feature_slug)`**: Returns deployment timing\n   - When can we deploy?\n   - Which environment?\n   - Are there any restrictions?\n\n3. **`fetch_support_contacts(audience_role)`**: Returns stakeholders to notify\n   - Who needs updates?\n   - How do we reach them?\n   - Where do we escalate issues?\n\n4. **`list_slo_watch_items(feature_slug)`**: Returns reliability concerns\n   - What performance metrics matter?\n   - What could go wrong?\n\n#### Implementation Notes\nFor this lab, we use **in-memory dictionaries** as our data store. In a production system, these would call:\n- Database queries\n- External APIs\n- Configuration management systems\n\nCapture deterministic product data in `app/services/agent_tools.py` so the agent can make realistic decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54450c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tools_path = Path('ai-web/backend/app/services/agent_tools.py')\n",
    "tools_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "tools_path.write_text('\"\"\"Deterministic tool helpers used by the release readiness agent.\"\"\"\\n\\nfrom __future__ import annotations\\n\\nfrom datetime import date\\nfrom typing import Literal\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass FeatureBrief(BaseModel):\\n    \"\"\"Condensed product brief for a feature under development.\"\"\"\\n\\n    slug: str\\n    name: str\\n    summary: str\\n    audience_role: str\\n    audience_experience: Literal[\"beginner\", \"intermediate\", \"advanced\"]\\n    success_metric: str\\n\\n\\nclass LaunchWindow(BaseModel):\\n    \"\"\"Deployment window information tracked by the release team.\"\"\"\\n\\n    feature_slug: str\\n    environment: Literal[\"staging\", \"production\"]\\n    window_start: date\\n    window_end: date\\n    freeze_required: bool = Field(default=True)\\n    notes: str = Field(default=\"\")\\n\\n\\nclass SupportContact(BaseModel):\\n    \"\"\"Contact details for teams who need proactive updates.\"\"\"\\n\\n    audience: str\\n    contact: str\\n    escalation_channel: str\\n\\n\\n_FEATURE_BRIEFS: dict[str, FeatureBrief] = {\\n    \"curriculum-pathways\": FeatureBrief(\\n        slug=\"curriculum-pathways\",\\n        name=\"Curriculum Pathways\",\\n        summary=(\\n            \"Surface sequenced lab recommendations so instructors can scaffold lessons \"\\n            \"for students based on prior completions.\"\\n        ),\\n        audience_role=\"Instructor\",\\n        audience_experience=\"intermediate\",\\n        success_metric=\"90% of instructors adopt generated pathways for the next cohort\",\\n    ),\\n    \"team-analytics\": FeatureBrief(\\n        slug=\"team-analytics\",\\n        name=\"Team Analytics Dashboard\",\\n        summary=\"Deliver a consolidated dashboard that highlights agent usage and completion trends for admins.\",\\n        audience_role=\"Program Manager\",\\n        audience_experience=\"advanced\",\\n        success_metric=\"Daily active program managers increase by 25%\",\\n    ),\\n}\\n\\n_LAUNCH_WINDOWS: dict[str, LaunchWindow] = {\\n    \"curriculum-pathways\": LaunchWindow(\\n        feature_slug=\"curriculum-pathways\",\\n        environment=\"production\",\\n        window_start=date(2025, 3, 10),\\n        window_end=date(2025, 3, 12),\\n        freeze_required=True,\\n        notes=\"Coordinated release with marketing webinar on Mar 11.\",\\n    ),\\n    \"team-analytics\": LaunchWindow(\\n        feature_slug=\"team-analytics\",\\n        environment=\"production\",\\n        window_start=date(2025, 4, 2),\\n        window_end=date(2025, 4, 4),\\n        freeze_required=True,\\n        notes=\"Requires feature flag rollout 48 hours prior to launch.\",\\n    ),\\n}\\n\\n_SUPPORT_DIRECTORY: dict[str, list[SupportContact]] = {\\n    \"Instructor\": [\\n        SupportContact(\\n            audience=\"Instructor\",\\n            contact=\"education-success@example.com\",\\n            escalation_channel=\"#instructor-support\",\\n        ),\\n        SupportContact(\\n            audience=\"Instructor\",\\n            contact=\"pedagogy-lead@example.com\",\\n            escalation_channel=\"#curriculum-updates\",\\n        ),\\n    ],\\n    \"Program Manager\": [\\n        SupportContact(\\n            audience=\"Program Manager\",\\n            contact=\"program-ops@example.com\",\\n            escalation_channel=\"#program-ops\",\\n        ),\\n    ],\\n}\\n\\n_SLO_WATCH_ITEMS: dict[str, list[str]] = {\\n    \"curriculum-pathways\": [\\n        \"Lesson ingestion latency must stay under 2 minutes\",\\n        \"Planner responses require >95% schema compliance\",\\n    ],\\n    \"team-analytics\": [\\n        \"Dashboard queries should resolve under 1.5 seconds\",\\n        \"Background aggregation jobs must remain below 75% CPU utilization\",\\n    ],\\n}\\n\\n\\ndef fetch_feature_brief(feature_slug: str) -> FeatureBrief:\\n    \"\"\"Return the canonical product brief for the requested feature.\"\"\"\\n\\n    brief = _FEATURE_BRIEFS.get(feature_slug)\\n    if brief is None:\\n        raise KeyError(feature_slug)\\n    return brief\\n\\n\\ndef fetch_launch_window(feature_slug: str) -> LaunchWindow:\\n    \"\"\"Fetch the release window associated with the feature.\"\"\"\\n\\n    window = _LAUNCH_WINDOWS.get(feature_slug)\\n    if window is None:\\n        raise KeyError(feature_slug)\\n    return window\\n\\n\\ndef fetch_support_contacts(audience_role: str) -> list[SupportContact]:\\n    \"\"\"Return the set of contacts who should be looped in for updates.\"\"\"\\n\\n    contacts = _SUPPORT_DIRECTORY.get(audience_role)\\n    if contacts:\\n        return contacts\\n    return [\\n        SupportContact(\\n            audience=audience_role,\\n            contact=\"success@example.com\",\\n            escalation_channel=\"#general-updates\",\\n        )\\n    ]\\n\\n\\ndef list_slo_watch_items(feature_slug: str) -> list[str]:\\n    \"\"\"List performance and reliability signals for the feature.\"\"\"\\n\\n    return _SLO_WATCH_ITEMS.get(feature_slug, [])\\n')\n",
    "print('Agent tool helpers ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708bd7b",
   "metadata": {},
   "source": [
    "### Step 2: Release readiness agent service\nImplement `app/services/agent.py` to orchestrate tool calls and produce structured recommendations.\n\n#### What Is an Agent Service?\nAn agent service is the **orchestration layer** that:\n1. **Calls tools** in a specific order\n2. **Combines results** into a coherent response\n3. **Makes decisions** based on tool outputs\n4. **Structures recommendations** for humans to act on\n\nThink of it as a **conductor** coordinating an orchestra of tools.\n\n#### The Agent Workflow\n\nOur `run_release_readiness_agent()` function follows this flow:\n\n```\n1. Receive Context (feature_slug, launch_date, audience_role, etc.)\n       \u2193\n2. Call Tools to Gather Data\n   \u251c\u2500 fetch_feature_brief()      \u2192 Get product details\n   \u251c\u2500 fetch_launch_window()       \u2192 Get deployment window\n   \u251c\u2500 fetch_support_contacts()    \u2192 Get stakeholders\n   \u2514\u2500 list_slo_watch_items()      \u2192 Get reliability concerns\n       \u2193\n3. Generate Plan (call existing planner service)\n       \u2193\n4. Build Recommendations Based on Data\n   \u251c\u2500 If multiple contacts \u2192 recommend broadcast\n   \u251c\u2500 If risks present \u2192 recommend mitigation\n   \u2514\u2500 Always \u2192 recommend validation steps\n       \u2193\n5. Structure Output (AgentRunResult)\n   \u251c\u2500 Summary text\n   \u251c\u2500 Recommended actions\n   \u251c\u2500 Generated plan\n   \u2514\u2500 Tool call traces (for debugging)\n```\n\n#### Key Concepts\n\n**Pydantic Models for Type Safety**\n```python\nclass AgentRunContext(BaseModel):\n    \"\"\"Input to the agent - what the user wants to know\"\"\"\n    feature_slug: str\n    launch_date: date\n    audience_role: str\n    audience_experience: str\n\nclass AgentRunResult(BaseModel):\n    \"\"\"Output from the agent - structured recommendations\"\"\"\n    summary: str\n    recommended_actions: list[AgentRecommendation]\n    plan: Plan\n    tool_calls: list[AgentToolCall]\n```\n\n**Error Handling**\n```python\ntry:\n    brief = fetch_feature_brief(context.feature_slug)\nexcept KeyError as exc:\n    raise AgentServiceError(\"Feature not found\") from exc\n```\n- Catch specific exceptions\n- Raise custom exceptions with helpful messages\n- Preserve the original error for debugging\n\n**Tool Call Logging**\n```python\ntool_calls = [\n    AgentToolCall(\n        tool=\"fetch_feature_brief\",\n        arguments={\"feature_slug\": \"curriculum-pathways\"},\n        output_preview=\"Curriculum Pathways: Surface sequenced...\"\n    )\n]\n```\nThis creates an **audit trail** showing:\n- Which tools were called\n- What arguments were passed\n- What they returned\n\n#### Teaching Moment: Why This Architecture?\n\n**Without an agent service:**\n```python\n# Router directly calls tools (bad!)\n@router.post(\"/release-readiness\")\ndef endpoint(payload):\n    brief = fetch_feature_brief(payload.feature_slug)\n    window = fetch_launch_window(payload.feature_slug)\n    # ... mixing business logic with HTTP handling\n```\n\n**With an agent service:**\n```python\n# Router delegates to service (good!)\n@router.post(\"/release-readiness\")\ndef endpoint(payload):\n    return run_release_readiness_agent(payload)\n```\n\nBenefits:\n- Router stays thin and focused on HTTP concerns\n- Service can be tested without a web server\n- Service can be reused by CLI tools, background jobs, etc.\n\nImplement `app/services/agent.py` to orchestrate tool calls and produce structured recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70444e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "agent_service_path = Path('ai-web/backend/app/services/agent.py')\n",
    "agent_service_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "agent_service_path.write_text('\"\"\"Release readiness agent service orchestrating deterministic tool calls.\"\"\"\\n\\nfrom __future__ import annotations\\n\\nfrom datetime import date\\nfrom typing import Any, Literal\\n\\nfrom pydantic import BaseModel, Field\\n\\nfrom app.schemas.planner import Plan, PlanRequest\\nfrom app.services.agent_tools import (\\n    FeatureBrief,\\n    LaunchWindow,\\n    SupportContact,\\n    fetch_feature_brief,\\n    fetch_launch_window,\\n    fetch_support_contacts,\\n    list_slo_watch_items,\\n)\\nfrom app.services.planner import build_plan\\n\\n\\nclass AgentServiceError(RuntimeError):\\n    \"\"\"Raised when the agent cannot complete its workflow.\"\"\"\\n\\n\\nclass AgentToolCall(BaseModel):\\n    \"\"\"Trace of a tool invocation the agent performed.\"\"\"\\n\\n    tool: str\\n    arguments: dict[str, Any]\\n    output_preview: str\\n\\n\\nclass AgentRecommendation(BaseModel):\\n    \"\"\"Action item recommended by the agent.\"\"\"\\n\\n    title: str\\n    detail: str\\n\\n\\nclass AgentRunContext(BaseModel):\\n    \"\"\"Input payload submitted by the frontend.\"\"\"\\n\\n    feature_slug: str = Field(..., min_length=2, max_length=40)\\n    launch_date: date\\n    audience_role: str = Field(..., min_length=2, max_length=60)\\n    audience_experience: Literal[\"beginner\", \"intermediate\", \"advanced\"]\\n    include_risks: bool = Field(default=True)\\n\\n\\nclass AgentRunResult(BaseModel):\\n    \"\"\"Structured result returned to the frontend.\"\"\"\\n\\n    summary: str\\n    recommended_actions: list[AgentRecommendation]\\n    plan: Plan\\n    tool_calls: list[AgentToolCall]\\n\\n\\ndef run_release_readiness_agent(context: AgentRunContext) -> AgentRunResult:\\n    \"\"\"Coordinate tool calls to prepare a release readiness brief.\"\"\"\\n\\n    try:\\n        brief: FeatureBrief = fetch_feature_brief(context.feature_slug)\\n    except KeyError as exc:\\n        raise AgentServiceError(f\"Unknown feature \\'{context.feature_slug}\\'.\") from exc\\n\\n    try:\\n        launch_window: LaunchWindow = fetch_launch_window(context.feature_slug)\\n    except KeyError as exc:\\n        raise AgentServiceError(\\n            f\"Launch window data is missing for feature \\'{context.feature_slug}\\'.\"\\n        ) from exc\\n\\n    contacts: list[SupportContact] = fetch_support_contacts(context.audience_role)\\n    slo_watch_items: list[str] = list_slo_watch_items(context.feature_slug)\\n\\n    tool_calls = [\\n        AgentToolCall(\\n            tool=\"fetch_feature_brief\",\\n            arguments={\"feature_slug\": context.feature_slug},\\n            output_preview=f\"{brief.name}: {brief.summary}\",\\n        ),\\n        AgentToolCall(\\n            tool=\"fetch_launch_window\",\\n            arguments={\"feature_slug\": context.feature_slug},\\n            output_preview=(\\n                f\"{launch_window.environment} window {launch_window.window_start.isoformat()}\"\\n                f\" \u2192 {launch_window.window_end.isoformat()}\"\\n            ),\\n        ),\\n        AgentToolCall(\\n            tool=\"fetch_support_contacts\",\\n            arguments={\"audience_role\": context.audience_role},\\n            output_preview=f\"{len(contacts)} contact(s) notified\",\\n        ),\\n    ]\\n\\n    if slo_watch_items:\\n        tool_calls.append(\\n            AgentToolCall(\\n                tool=\"list_slo_watch_items\",\\n                arguments={\"feature_slug\": context.feature_slug},\\n                output_preview=\", \".join(slo_watch_items[:2]),\\n            )\\n        )\\n\\n    plan_request = PlanRequest(\\n        goal=f\"Launch {brief.name} successfully\",\\n        audience_role=context.audience_role,\\n        audience_experience=context.audience_experience,  # type: ignore[arg-type]\\n        primary_risk=slo_watch_items[0] if context.include_risks and slo_watch_items else None,\\n    )\\n    plan: Plan = build_plan(plan_request)\\n\\n    summary = (\\n        f\"{brief.name} targets {brief.audience_role} personas. \"\\n        f\"Production window: {launch_window.window_start:%b %d}\u2013{launch_window.window_end:%b %d}. \"\\n        f\"Success metric: {brief.success_metric}.\"\\n    )\\n\\n    recommended_actions: list[AgentRecommendation] = [\\n        AgentRecommendation(\\n            title=\"Confirm launch communications\",\\n            detail=(\\n                f\"Share the feature brief with {contacts[0].contact} and align on messaging for the \"\\n                f\"{launch_window.environment} window.\"\\n            ),\\n        ),\\n        AgentRecommendation(\\n            title=\"Validate operational readiness\",\\n            detail=(\\n                \"Ensure runbooks and dashboards reflect the new flow. Coordinate with site reliability \"\\n                \"for rollout approval.\"\\n            ),\\n        ),\\n    ]\\n\\n    if context.include_risks and slo_watch_items:\\n        recommended_actions.append(\\n            AgentRecommendation(\\n                title=\"Mitigate top risk\",\\n                detail=f\"Create a mitigation plan for: {slo_watch_items[0]}.\",\\n            )\\n        )\\n\\n    if len(contacts) > 1:\\n        recommended_actions.append(\\n            AgentRecommendation(\\n                title=\"Broadcast stakeholder update\",\\n                detail=(\\n                    \"Send a tailored update to secondary contacts so downstream teams can prepare \"\\n                    \"training materials and support docs.\"\\n                ),\\n            )\\n        )\\n\\n    return AgentRunResult(\\n        summary=summary,\\n        recommended_actions=recommended_actions,\\n        plan=plan,\\n        tool_calls=tool_calls,\\n    )\\n')\n",
    "print('Agent service module updated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666451f",
   "metadata": {},
   "source": [
    "### Step 3: API router\nExpose the agent through FastAPI using `app/routers/agent.py` so the frontend can call it.\n\n#### What Is a FastAPI Router?\nA router is the **HTTP interface** to your agent. It:\n- Defines URL endpoints (`/ai/release-readiness`)\n- Validates incoming requests (Pydantic does this automatically)\n- Calls the service layer\n- Serializes responses to JSON\n- Handles HTTP errors (404, 500, etc.)\n\n#### Router Best Practices\n\n**Keep it thin**\n```python\n@router.post(\"/release-readiness\", response_model=AgentRunResult)\ndef release_readiness(payload: AgentRunContext) -> AgentRunResult:\n    try:\n        return run_release_readiness_agent(payload)\n    except AgentServiceError as exc:\n        raise HTTPException(status_code=404, detail=str(exc)) from exc\n```\n\nThis router:\n- Receives a Pydantic model (`AgentRunContext`)\n- Returns a Pydantic model (`AgentRunResult`)\n- Converts service errors to HTTP errors\n- Does NOT contain business logic\n\n**Why use `response_model`?**\n- FastAPI generates OpenAPI documentation automatically\n- Response validation ensures you return what you promise\n- Frontend developers know exactly what to expect\n\n#### Error Handling Strategy\n\n```python\ntry:\n    return run_release_readiness_agent(payload)\nexcept AgentServiceError as exc:\n    # Business logic error \u2192 404 (not found)\n    raise HTTPException(status_code=404, detail=str(exc)) from exc\nexcept Exception:\n    # Unexpected error \u2192 500 (server error)\n    # FastAPI handles this automatically\n    raise\n```\n\nExpose the agent through FastAPI using `app/routers/agent.py` so the frontend can call it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42558454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "agent_router_path = Path('ai-web/backend/app/routers/agent.py')\n",
    "agent_router_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "agent_router_path.write_text('\"\"\"Agent endpoints that power the Lab 05 release readiness workflow.\"\"\"\\n\\nfrom __future__ import annotations\\n\\nfrom fastapi import APIRouter, HTTPException\\n\\nfrom app.services.agent import (\\n    AgentRunContext,\\n    AgentRunResult,\\n    AgentServiceError,\\n    run_release_readiness_agent,\\n)\\n\\nrouter = APIRouter(prefix=\"/ai\", tags=[\"ai\"])\\n\\n\\n@router.post(\"/release-readiness\", response_model=AgentRunResult)\\ndef release_readiness(payload: AgentRunContext) -> AgentRunResult:\\n    \"\"\"Run the deterministic agent pipeline and surface structured output.\"\"\"\\n\\n    try:\\n        return run_release_readiness_agent(payload)\\n    except AgentServiceError as exc:\\n        raise HTTPException(status_code=404, detail=str(exc)) from exc\\n')\n",
    "print('Agent router available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0d1cc",
   "metadata": {},
   "source": [
    "### Step 4: Confirm router registration\nEnsure `app/main.py` includes the new agent router alongside existing imports.\n\n#### Router Registration in FastAPI\n\nFastAPI needs to know about your router before it can handle requests. This happens in `app/main.py`.\n\n#### The Registration Process\n\n1. **Import the router**\n   ```python\n   from app.routers.agent import router as agent_router\n   ```\n\n2. **Include it in the app**\n   ```python\n   app.include_router(agent_router)\n   ```\n\n3. **Routers are modular**\n   Each router can have:\n   - Its own prefix (`/ai`, `/chat`, `/planner`)\n   - Its own tags (for OpenAPI grouping)\n   - Its own dependencies (auth, rate limiting, etc.)\n\n#### Teaching Moment: Why Routers?\n\n**Without routers** (all endpoints in main.py):\n```python\n# main.py becomes a giant file\n@app.post(\"/ai/release-readiness\")\ndef release_readiness(...): ...\n\n@app.post(\"/ai/sentiment-analysis\")\ndef sentiment_analysis(...): ...\n\n@app.post(\"/chat/message\")\ndef chat_message(...): ...\n# ... 50 more endpoints\n```\n\n**With routers** (organized by feature):\n```python\n# main.py stays clean\napp.include_router(agent_router)   # All /ai/* endpoints\napp.include_router(chat_router)    # All /chat/* endpoints\napp.include_router(planner_router) # All /planner/* endpoints\n```\n\nBenefits:\n- **Organization**: Related endpoints live together\n- **Team collaboration**: Different teams can own different routers\n- **Reusability**: Routers can be packaged and shared\n\nEnsure `app/main.py` includes the new agent router alongside existing imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "main_path = Path('ai-web/backend/app/main.py')\n",
    "text = main_path.read_text()\n",
    "if 'agent_router' not in text:\n",
    "    text = text.replace(\"from app.routers.echo import router as echo_router\\nfrom app.routers.gemini import router as gemini_router\\n\",\n",
    "        \"from app.routers.agent import router as agent_router\\nfrom app.routers.echo import router as echo_router\\nfrom app.routers.gemini import router as gemini_router\\nfrom app.routers.planner import router as planner_router\\n\")\n",
    "    text = text.replace(\"app.include_router(echo_router)\\napp.include_router(gemini_router)\\n\",\n",
    "        \"app.include_router(agent_router)\\napp.include_router(echo_router)\\napp.include_router(gemini_router)\\napp.include_router(planner_router)\\n\")\n",
    "    main_path.write_text(text)\n",
    "    print('Agent router registered in FastAPI app.')\n",
    "else:\n",
    "    print('Agent router already configured.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26208bf4",
   "metadata": {},
   "source": [
    "### Step 5: Execute the agent locally\nCall the service helper directly to preview the structured JSON returned to the frontend.\n\n#### Testing the Agent Directly\n\nBefore testing through HTTP, let's call the agent function directly. This is useful for:\n- **Debugging**: See the full output without HTTP overhead\n- **Development**: Iterate quickly without restarting the server\n- **Understanding**: See exactly what data flows through the system\n\n#### What to Look For\n\nWhen you call `run_release_readiness_agent()`, inspect:\n\n1. **Summary**: Is it clear and actionable?\n2. **Recommended actions**: Do they make sense given the input?\n3. **Tool calls**: Were the right tools called with the right arguments?\n4. **Plan**: Does the nested planner output integrate smoothly?\n\n#### Expected Output Structure\n\n```json\n{\n  \"summary\": \"Curriculum Pathways targets Instructor personas...\",\n  \"recommended_actions\": [\n    {\n      \"title\": \"Confirm launch communications\",\n      \"detail\": \"Share the feature brief with...\"\n    },\n    {\n      \"title\": \"Validate operational readiness\",\n      \"detail\": \"Ensure runbooks and dashboards...\"\n    }\n  ],\n  \"plan\": {\n    \"goal\": \"Launch Curriculum Pathways successfully\",\n    \"steps\": [...],\n    \"risk_mitigations\": [...]\n  },\n  \"tool_calls\": [\n    {\n      \"tool\": \"fetch_feature_brief\",\n      \"arguments\": {\"feature_slug\": \"curriculum-pathways\"},\n      \"output_preview\": \"Curriculum Pathways: Surface...\"\n    }\n  ]\n}\n```\n\n#### Teaching Moment: Direct vs HTTP Testing\n\n**Direct function call** (faster iteration):\n```python\nresult = run_release_readiness_agent(context)\nprint(result.model_dump())\n```\n\n**HTTP request** (tests the full stack):\n```bash\ncurl -X POST http://localhost:8000/ai/release-readiness \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"feature_slug\":\"curriculum-pathways\",...}'\n```\n\nBoth are valuable:\n- Use direct calls during development\n- Use HTTP requests for integration testing\n\nCall the service helper directly to preview the structured JSON returned to the frontend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2edbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "from app.services.agent import AgentRunContext, run_release_readiness_agent\n",
    "\n",
    "context = AgentRunContext(\n",
    "    feature_slug='curriculum-pathways',\n",
    "    launch_date=date(2025, 3, 10),\n",
    "    audience_role='Instructor',\n",
    "    audience_experience='intermediate',\n",
    ")\n",
    "\n",
    "result = run_release_readiness_agent(context)\n",
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805f56f",
   "metadata": {},
   "source": [
    "## Validation / acceptance checks\n```bash\n# locally\ncurl -X POST http://localhost:8000/ai/release-readiness \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"feature_slug\":\"curriculum-pathways\",\"launch_date\":\"2025-03-10\",\"audience_role\":\"Instructor\",\"audience_experience\":\"intermediate\"}'\n```\n- The response includes a summary, recommended actions, tool call traces, and a nested planner payload.\n- The FastAPI interactive docs (`/docs`) display the new endpoint under the **ai** tag.\n- React development mode renders the structured agent output without runtime warnings.\n\n### What to Verify\n\nAfter implementing all steps, test that:\n\n1. **The endpoint responds**: `curl` succeeds with 200 OK\n2. **The response is structured**: JSON contains `summary`, `recommended_actions`, `plan`, `tool_calls`\n3. **The documentation works**: FastAPI docs (`/docs`) show the endpoint with correct schemas\n4. **Error handling works**: Invalid input returns helpful error messages\n\n### Manual Testing\n\n```bash\n# locally\ncurl -X POST http://localhost:8000/ai/release-readiness \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"feature_slug\":\"curriculum-pathways\",\"launch_date\":\"2025-03-10\",\"audience_role\":\"Instructor\",\"audience_experience\":\"intermediate\"}'\n```\n\n### Expected Success Criteria\n\n- \u2705 The response includes a summary, recommended actions, tool call traces, and a nested planner payload\n- \u2705 The FastAPI interactive docs (`/docs`) display the new endpoint under the **ai** tag\n- \u2705 React development mode renders the structured agent output without runtime warnings\n\n### Debugging Tips\n\n**If you get 404:**\n- Check that the router is registered in `main.py`\n- Verify the URL path matches the router prefix + endpoint path\n\n**If you get 422 (validation error):**\n- Check that your request body matches `AgentRunContext` schema\n- Ensure date is formatted as `YYYY-MM-DD`\n\n**If you get 500:**\n- Check server logs for Python exceptions\n- Verify all tools are returning expected data types\n- Ensure no typos in dictionary keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b83fcb",
   "metadata": {},
   "source": [
    "## Homework / extensions\n- Add more feature briefs and launch windows to the tool module, then branch the agent logic based on feature type.\n- Persist agent responses or tool call traces to an analytics datastore for auditing.\n- Connect the agent output to the frontend planner UI so students can compare generated steps against the release readiness summary.\n\n### Extension Ideas for Teaching\n\n1. **Add more feature briefs and launch windows** to the tool module\n   - Create 3-5 additional features\n   - Branch the agent logic based on feature type\n   - *Teaching moment*: Show how tools scale independently of agent logic\n\n2. **Persist agent responses** to an analytics datastore for auditing\n   - Add a new database table for agent runs\n   - Store tool call traces for debugging\n   - *Teaching moment*: Observability in production systems\n\n3. **Connect the agent output** to the frontend planner UI\n   - Add a new React component for agent responses\n   - Compare generated steps against the release readiness summary\n   - *Teaching moment*: Full-stack integration\n\n4. **Add conditional logic** to recommendations\n   - If feature is high-risk, require additional sign-offs\n   - If launch window is close, recommend freeze procedures\n   - *Teaching moment*: Building intelligence into deterministic agents\n\n5. **Create unit tests** for each layer\n   - Test tools in isolation with mock data\n   - Test agent service with mock tools\n   - Test router with mock service\n   - *Teaching moment*: Testing strategy for layered architectures\n\n### Advanced Challenges\n\n- **Replace mock data** with real database queries\n- **Add caching** to avoid repeated tool calls\n- **Implement retries** for flaky tool calls\n- **Add rate limiting** to protect the endpoint\n- **Create an agent CLI** that uses the same service layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bcfa1e",
   "metadata": {},
   "source": [
    "\n",
    "## Updated full-stack template walkthrough\n",
    "\n",
    "This lab now uses a Postgres-backed stack managed through Alembic migrations and Docker Compose.\n",
    "\n",
    "- **Database + Alembic**: `backend/alembic/env.py` and `backend/alembic/versions/20250212_initial.py` create tables for echo retries, planner runs, course resources, and RAG document chunks. Run migrations with `alembic upgrade head` (the backend container executes this automatically on start).\n",
    "- **FastAPI wiring**: `backend/app/database.py` exposes a SQLAlchemy `SessionLocal` dependency. Routers like `app/routers/echo.py`, `app/routers/planner.py`, and `app/routers/resources.py` read and write real rows instead of in-memory mocks.\n",
    "- **Docker Compose + Nginx**: `docker-compose.yml` now launches Postgres, FastAPI (with migrations), the Vite dev server, and an Nginx reverse proxy (`nginx/default.conf`) that fronts both the API (`/api`) and frontend assets.\n",
    "- **RAG chatbot**: `app/services/rag.py` indexes seeded `DocumentChunk` rows, while `app/services/chatbot.py` blends retrieval with Gemini when `GEMINI_API_KEY` is configured. The `/chat` route exposes the agent-like flow and the React `ChatPanel` renders responses and retrieved context.\n",
    "- **New end-to-end feature**: The `resources` table powers the Resource Board UI (`frontend/src/features/resources`) so students can add persistent links. Planner history (`frontend/src/features/planner`) and echo retries now read from Postgres as well.\n",
    "\n",
    "### How to run the stack with Docker Compose\n",
    "\n",
    "1. `cd ai-web`\n",
    "2. `docker compose up --build`\n",
    "3. Open http://localhost:8080 to reach Nginx. API requests are proxied to FastAPI at `/api`. Postgres data lives in the `db_data` volume.\n",
    "\n",
    "### Creating and applying new migrations\n",
    "\n",
    "1. Enter the backend container: `docker compose exec backend bash`\n",
    "2. Generate a migration: `alembic revision -m \"describe change\" --autogenerate`\n",
    "3. Apply migrations: `alembic upgrade head`\n",
    "\n",
    "### Testing the new features\n",
    "\n",
    "- **Echo retry + persistence**: Submit the echo form; the \"Recent echo attempts\" list should update from the `echo_attempts` table.\n",
    "- **Resource Board**: Add a URL in the Resource Board. Refreshing the page keeps entries thanks to the `resources` table.\n",
    "- **Planner + history**: Generate a plan in the Planner panel; the newest plan appears in the history list powered by the `plan_runs` table.\n",
    "- **Chatbot/agent UI**: Ask deployment or migration questions in the chatbot. Retrieved context from `document_chunks` is displayed alongside agent steps; Gemini responses are used when `GEMINI_API_KEY` is provided.\n",
    "\n",
    "Refer to the updated source files when walking through the lab so students can trace how migrations, database sessions, and the React UI connect end to end.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}